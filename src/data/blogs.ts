export interface BlogPost {
    id: string;
    title: string;
    description: string;
    type: 'blog';
    tags: string[];
    image?: string;
    content: string; // Markdown content
    date: string;
    readTime: string;
    author: string;
}

export const blogs: BlogPost[] = [
    {
        id: '5',
        title: 'Speaking Too Much Without Thinking: A Developer\'s Trap',
        description: 'Communication is a skill, and over-explaining or speaking impulsively can hurt your credibility. Learn why silence is often better than noise.',
        type: 'blog',
        tags: ['Self Improvement', 'Communication', 'Soft Skills', 'Career Growth'],
        date: 'Feb 15, 2024',
        readTime: '6 min read',
        author: 'Abhinay Tiwari',
        content: `
# Speaking Too Much Without Thinking: A Developer‚Äôs Trap

**Why thoughtful communication is a hidden superpower in software teams**

In tech, we celebrate problem-solvers, innovators, and great communicators. But there‚Äôs a subtle trap many developers fall into ‚Äî talking too much without thinking first. It seems harmless, even natural in collaborative environments, yet it quietly damages clarity, slows teams down, and reveals gaps in understanding.

In a world where every word can shift decisions, create direction, or cause confusion, mastering mindful communication becomes just as important as mastering code.

## When Words Move Faster Than Thoughts

Developers spend hours debugging, optimizing, and structuring logic. Ironically, the same level of structure often disappears the moment we open our mouths.
The result?

- Long explanations that don‚Äôt land
- Thinking out loud in meetings instead of delivering conclusions
- Rambling through solutions instead of presenting insights
- Dominating conversations unintentionally

It‚Äôs not a flaw ‚Äî it‚Äôs a habit. But a dangerous one.

Teams don‚Äôt just collaborate on code; they collaborate on clarity. When you speak without thinking, you introduce noise where there should be signal.

## The Cost of Over-Talking in Tech Teams

Over-communication isn‚Äôt the same as effective communication. Speaking too much, too fast, or without direction creates several issues:

### 1. It dilutes your message
The more you speak, the less people remember. Developers respect concise communication because it reflects clarity of thought.

### 2. It slows down discussions
Meetings stretch, decisions delay, and focus shifts. One unfocused explanation can derail an entire conversation.

### 3. It signals unclear thinking
A developer who rambles often appears unsure, even if they know their stuff. Clear communication builds trust; chaotic communication breaks it.

### 4. It unintentionally overshadows quieter teammates
Some of the best ideas come from people who don‚Äôt fight for airtime. Over-talking can silence them.

## Why Great Developers Speak Less, but Say More

Senior engineers aren‚Äôt quieter because they know less ‚Äî they‚Äôre quieter because they think more.

Before speaking, they pause.
Before answering, they reflect.
Before explaining, they structure.

This pause is powerful.
It shows maturity, confidence, and respect for everyone‚Äôs time.

When they finally speak, people listen ‚Äî because their words carry weight, not noise.

## Develop the Discipline of Thoughtful Speaking

Here‚Äôs a simple framework developers can adopt:

### 1. Listen fully before forming an opinion
Most misunderstandings begin because we respond before the other person is even finished.

### 2. Think in bullet points, speak in clarity
Structure your thoughts like your code ‚Äî modular, simple, readable.

### 3. Ask yourself: ‚ÄúIs this necessary?‚Äù
Just like unnecessary code is removed during refactoring, unnecessary speech can be eliminated too.

### 4. Respect silence
Silence isn‚Äôt awkward; it‚Äôs processing time. It shows you think before reacting.

### 5. Keep it short, then offer depth on request
Give the summary first. Details only if someone asks.

## The Developer Who Thinks Before Speaking Wins

A developer who speaks with intention becomes:

- Easier to collaborate with
- More respected in discussions
- More trusted in decision-making
- More impactful in leadership roles

Your words become your architecture.
Your clarity becomes your design.
Your communication becomes your legacy.

In a profession built on logic, it‚Äôs time we bring that logic to how we speak.

**Think. Then speak.**
**Not the other way around.**
        `
    },
    {
        id: '1',
        title: 'Mastering the Sliding Window Technique',
        description: 'A developer\'s guide to writing faster, cleaner, and smarter algorithms',
        type: 'blog',
        tags: ['Algorithms', 'Sliding Window', 'DSA', 'Efficiency'],
        date: 'Oct 24, 2023',
        readTime: '12 min read',
        author: 'AlgoExpert',
        content: `
# Mastering the Sliding Window Technique

**A developer's guide to writing faster, cleaner, and smarter algorithms**

## Introduction

Many developers struggle with array and string problems‚Äînot because they are hard, but because they solve them the slow way.

If you've ever written:

- nested loops
- recalculated sums repeatedly
- or hit a TLE (Time Limit Exceeded) on LeetCode

then the Sliding Window Technique is exactly what you need.

**Sliding Window is not a trick.**  
It's a thinking pattern‚Äîone that converts brute-force solutions into optimal ones.

## What Is the Sliding Window Technique?

Sliding Window is used when:

‚úÖ You're dealing with arrays or strings  
‚úÖ You need information about a contiguous subarray or substring  
‚úÖ You want to reuse previous computation instead of recomputing

Instead of restarting work for every position, you:

1. Expand the window
2. Update the result
3. Shrink the window when needed

This reduces time complexity from **O(n¬≤) to O(n)**.

---

## Types of Sliding Window

There are two major types you must master.

### 1. Fixed Size Sliding Window

**When to Use**

Window size \`k\` is given

**Examples:**

- Maximum sum subarray of size k
- Average of subarrays
- Count of fixed-length patterns

**Example Problem**

Find the maximum sum of a subarray of size \`k\`

**Brute Force (Wrong Way)**

<!-- MULTILANG_START -->
\`\`\`python
for i in range(n - k + 1):
    sum_val = 0
    for j in range(i, i + k):
        sum_val += arr[j]
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
for (int i = 0; i <= n - k; i++) {
    int sum = 0;
    for (int j = i; j < i + k; j++) {
        sum += arr[j];
    }
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
for (int i = 0; i <= n - k; i++) {
    int sum = 0;
    for (int j = i; j < i + k; j++) {
        sum += arr[j];
    }
}
\`\`\`
<!-- MULTILANG_END -->

‚õî O(n¬≤)

**Optimized Sliding Window (Correct Way)**

<!-- MULTILANG_START -->
\`\`\`python
max_sum = 0
window_sum = 0

# Calculate sum of first window
for i in range(k):
    window_sum += arr[i]

max_sum = window_sum

# Slide the window
for i in range(k, len(arr)):
    window_sum += arr[i]      # add next element
    window_sum -= arr[i - k]  # remove first element
    max_sum = max(max_sum, window_sum)
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
int maxSum = 0, windowSum = 0;

// Calculate sum of first window
for (int i = 0; i < k; i++) {
    windowSum += arr[i];
}

maxSum = windowSum;

// Slide the window
for (int i = k; i < arr.length; i++) {
    windowSum += arr[i];      // add next element
    windowSum -= arr[i - k];  // remove first element
    maxSum = Math.max(maxSum, windowSum);
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
int maxSum = 0, windowSum = 0;

// Calculate sum of first window
for (int i = 0; i < k; i++) {
    windowSum += arr[i];
}

maxSum = windowSum;

// Slide the window
for (int i = k; i < n; i++) {
    windowSum += arr[i];      // add next element
    windowSum -= arr[i - k];  // remove first element
    maxSum = max(maxSum, windowSum);
}
\`\`\`
<!-- MULTILANG_END -->

‚úÖ O(n)  
‚úÖ No repeated computation

---

### 2. Variable Size Sliding Window

**When to Use**

- Window size is not fixed
- You expand and shrink based on a condition

**Examples:**

- Longest substring without repeating characters
- Smallest subarray with sum ‚â• target
- Longest substring with at most k distinct characters

**Core Pattern (Very Important)**

<!-- MULTILANG_START -->
\`\`\`python
left = 0

for right in range(n):
    # expand window (include right)
    
    while condition_is_violated:
        # shrink window (exclude left)
        left += 1
    
    # update answer
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
int left = 0;

for (int right = 0; right < n; right++) {
    // expand window (include right)
    
    while (condition is violated) {
        // shrink window (exclude left)
        left++;
    }
    
    // update answer
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
int left = 0;

for (int right = 0; right < n; right++) {
    // expand window (include right)
    
    while (condition is violated) {
        // shrink window (exclude left)
        left++;
    }
    
    // update answer
}
\`\`\`
<!-- MULTILANG_END -->

**Memorize this.**  
Most sliding window problems follow this structure.

---

## Example: Longest Substring Without Repeating Characters

**Problem**

Given a string, find the length of the longest substring without repeating characters.

**Approach**

- Use a HashSet
- Expand \`right\`
- If duplicate found ‚Üí shrink \`left\`

**Code**

<!-- MULTILANG_START -->
\`\`\`python
from collections import deque

char_set = set()
left = 0
max_len = 0

for right in range(len(s)):
    while s[right] in char_set:
        char_set.remove(s[left])
        left += 1
    
    char_set.add(s[right])
    max_len = max(max_len, right - left + 1)
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
Set<Character> set = new HashSet<>();
int left = 0, maxLen = 0;

for (int right = 0; right < s.length(); right++) {
    while (set.contains(s.charAt(right))) {
        set.remove(s.charAt(left));
        left++;
    }
    set.add(s.charAt(right));
    maxLen = Math.max(maxLen, right - left + 1);
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
#include <unordered_set>
#include <string>
#include <algorithm>

unordered_set<char> charSet;
int left = 0, maxLen = 0;

for (int right = 0; right < s.length(); right++) {
    while (charSet.find(s[right]) != charSet.end()) {
        charSet.erase(s[left]);
        left++;
    }
    charSet.insert(s[right]);
    maxLen = max(maxLen, right - left + 1);
}
\`\`\`
<!-- MULTILANG_END -->

‚úÖ Linear time  
‚úÖ Clean logic  
‚úÖ Interview-ready

---

## Sliding Window vs Two Pointers

Many people confuse these.

| Sliding Window | Two Pointers |
|----------------|--------------|
| Contiguous data | Can be non-contiguous |
| Dynamic window | Independent movement |
| Used for sums, counts | Used for comparisons |

üëâ **Sliding Window is actually a special case of Two Pointers.**

---

## Common Mistakes Developers Make

‚ùå Forgetting to shrink the window  
‚ùå Updating answer at the wrong time  
‚ùå Using nested loops when a window is enough  
‚ùå Not identifying whether the window is fixed or variable

---

## How to Identify Sliding Window Problems Quickly

Ask yourself:

1. Is the data **continuous**?
2. Am I checking **subarrays or substrings**?
3. Can I **reuse previous computation**?

If yes ‚Üí **Sliding Window.**

---

## Practice Problems (Must Do)

Start in this order:

1. Maximum Sum Subarray of Size K
2. First Negative Number in Every Window
3. Longest Substring Without Repeating Characters
4. Minimum Window Substring
5. Longest Subarray with Sum ‚â§ K

---

## Final Thoughts

Sliding Window is not just an algorithmic technique‚Äîit's a **mindset shift**.

Once you master it:

‚úÖ Your code becomes **faster**  
‚úÖ Your logic becomes **cleaner**  
‚úÖ Interviews become **easier**

If brute force feels natural to you right now, that's okay.  
Sliding Window is what comes after you stop thinking like a beginner.

**Think in windows. Not loops.**
        `
    },
    {
        id: '2',
        title: 'System Design Deep Dive: How to Build a Scalable URL Shortener (Like bit.ly or TinyURL)',
        description: 'A URL shortener looks simple on the surface‚Äîpaste a long link, get a short one back. But designing a real-world, planet-scale system like Bitly is not simple at all. You‚Äôre dealing with billions of redirects per day, extremely high read traffic, abuse protection, and more.',
        type: 'blog',
        tags: ['System Design', 'Scalability', 'Distributed Systems'],
        date: 'Nov 12, 2023',
        readTime: '12 min read',
        author: 'SystemArch',
        content: `
# System Design Deep Dive: How to Build a Scalable URL Shortener (Like bit.ly or TinyURL)

A URL shortener looks simple on the surface‚Äîpaste a long link, get a short one back.
But designing a real-world, planet-scale system like Bitly is not simple at all. You‚Äôre dealing with billions of redirects per day, extremely high read traffic, abuse protection, metadata extraction, analytics pipelines, caching layers, DB consistency, CDN routing, and infrastructure distributed around the globe.

This blog gives you every piece of knowledge you need to design a production-ready URL shortener‚Äîexactly the way system design interviews expect, and the way big companies actually deploy them.

Let‚Äôs get into the actual engineering.

## 1. Problem Statement

We want to design a service that:

- Shortens long URLs
- Redirects users from the short link to the original link
- Tracks analytics (click count, location, device, referrer, etc.)
- Supports custom aliases
- Handles billions of requests per month
- Maintains extremely low latency (< 50 ms for redirects)

Reads will be extremely high. Writes will be much lower.

**Realistic traffic ratio:** 1000 reads : 1 write

So everything must be optimized around fast, scalable reads.

## 2. Functional Requirements

- Generate a unique short URL for any long URL
- Support custom aliases (short.io/mybrand)
- Redirect instantly
- Track analytics
- Handle expiry (optional)
- Provide user accounts (optional)
- Provide an API for programmatic access

## 3. Non-Functional Requirements

- High availability (SERVING traffic globally 24/7)
- Low latency ‚Äî sub-50ms redirect
- Scalable system ‚Äî must grow horizontally
- Fault-tolerance ‚Äî no single point of failure
- Security ‚Äî prevent spam, malicious URLs, DDOS
- Eventually consistent analytics

**Redirects MUST be fast. Analytics can lag behind.**

## 4. High-Level Architecture

Here is the real layout of a production-grade shortener:

\`\`\`text
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ   CDN / Edge      ‚îÇ  ‚Üê First cache layer
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ API Gateway/LB   ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ     Application Layer   ‚îÇ  ‚Üê Stateless services
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ           Redis Cache         ‚îÇ  ‚Üê HOT redirects
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ   Primary Database     ‚îÇ  ‚Üê Postgres / DynamoDB / Cassandra
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   Analytics Pipeline   ‚îÇ (Kafka ‚Üí ClickHouse/BigQuery)
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
\`\`\`

## 5. Data Model

### Short URL Table

| Field | Description |
|-------|-------------|
| code (PK) | Short code (base62) |
| original_url | Actual URL |
| created_at | Timestamp |
| expire_at | Optional expiry |
| user_id | Owner (optional) |
| click_count | Counter (optional) |
| metadata | JSON: preview info, safety flags |
| is_custom | Whether it‚Äôs custom alias |

### Analytics (Event Table)

Append-only events:

| Field | Meaning |
|-------|---------|
| code | short code used |
| timestamp | click time |
| ip | user IP |
| user_agent | browser/device |
| referrer | source |
| country | geo data |

Analytics NEVER live in the main DB. That would destroy redirect latency.

## 6. URL Code Generation Strategies

This is a core system design point.
There are 4 main approaches:

### A. Auto-increment ID + Base62 (Most Common)

\`1\` ‚Üí "A"
\`1234567\` ‚Üí "BfG8"

**Pros:**
- No collisions
- Very simple
- Deterministic

**Cons:**
- Predictable (attackers can guess URLs)

### B. Random Code (Crypto-safe RNG)

Generate random 6‚Äì8 character base62 strings.

**Pros:**
- Unpredictable
- No sequence server

**Cons:**
- Need collision checks in DB
- Worst-case retries

### C. Hashing the original URL

Use MD5/SHA256 ‚Üí trim ‚Üí collision handling.

**Pros:**
- Same URL ‚Üí same code

**Cons:**
- Trimming causes collisions
- Not short enough naturally

### D. Snowflake IDs (Distributed Generator)

Twitter-style: time + machine + sequence bits.

**Pros:**
- Highly scalable
- No central bottleneck

**Cons:**
- Predictable pattern unless masked

**Which should you choose?**

For interviews + real world:
**Use Snowflake ID ‚Üí Base62 encoding.**
Predictability solved by adding a reversible secret permutation.

## 7. Redirect Flow (The Real Critical Path)

Your redirect must be fast.
A slow redirect = dead product.

Here‚Äôs the real sequence:

**GET /abc123**

1. CDN checks if redirect is cached ‚Üí if yes ‚Üí return instantly (3‚Äì10ms)
2. If miss ‚Üí API server receives request
3. API checks Redis (hot cache)
4. If miss ‚Üí fetch from DB
5. Store DB result in Redis
6. Return 301 redirect to original URL
7. Fire analytics event asynchronously

**Break anything here, and your entire service collapses under traffic.**

## 8. Storage Layer Options

### Option 1: Relational (Postgres/MySQL)

Use for small to medium scale.

**Pros:**
- Easy to query
- Strong consistency
- Simple indexes

**Cons:**
- Harder to scale horizontally

### Option 2: DynamoDB / Cassandra (NoSQL)

Used by large-scale systems.

**Pros:**
- Infinite scale
- Low latency
- No complex joins needed

**Cons:**
- Harder dev experience
- Eventual consistency quirks

## 9. Caching Strategy

This is the part most people mess up.
A shortener without aggressive caching is a failure.

### Layer 1: CDN caching

The 301/302 response itself is cached at edge POPs.

### Layer 2: Redis

Store:
\`\`\`json
key: short_code
value: {original_url, expire_at, metadata}
\`\`\`

**TTL example:** 1 hour

If the link changes, you purge CDN + Redis.

**Cache Hit Ratio Target:** 99%+

If you're hitting DB for redirects, your design is trash.

## 10. Analytics Pipeline

You NEVER track analytics in the main path.

Instead:
**API ‚Üí Kafka ‚Üí Stream Processor ‚Üí Data Warehouse**

### Tools commonly used:

| Layer | Technology |
|-------|------------|
| Queue | Kafka / Kinesis |
| Stream processing | Flink / Spark Streaming |
| Warehouse | BigQuery / ClickHouse / Snowflake |
| Dashboard | Metabase / Grafana |

Analytics is eventually consistent ‚Äî AND THAT‚ÄôS OK.

## 11. Handling Hot URLs (Viral Content)

Hot URLs get millions of hits per hour.
If your design doesn‚Äôt handle that, you're screwed.

**Solutions:**
- Edge cache heavily
- Redis cluster with sharding
- Pre-warm cache for trending links
- Rate-limit abusive IPs
- Use async replication for DB reads

## 12. Rate Limiting & Abuse Prevention

URL shorteners are spam magnets.
You must block malicious patterns.

**Techniques:**
- Per-IP and per-user throttling
- CAPTCHAs on suspicious traffic
- Block \`javascript:\` schemes
- Block malware domains
- User verification for large volume creators

## 13. Monitoring and Metrics

**Track:**
- 95th/99th percentile redirect latency
- Redis hit ratio
- DB read/write QPS
- 5xx and 4xx error rates
- Sequence generator failures
- CDN cache hit %

If latency spikes ‚Üí first suspect = redis miss + DB slowness.

## 14. Deployment & Scalability

- **Stateless services** ‚Üí run on Kubernetes/ECS
- **Redis** ‚Üí use cluster mode
- **DB** ‚Üí read replicas or multi-region setup
- **CDN** ‚Üí global (Cloudflare/Akamai)

A mature setup uses:
- Blue/green deployments
- Canary releases
- Automated rollbacks

## 15. Example Code Snippets

### Base62 Encoder
\`\`\`python
ALPHABET = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"

def base62_encode(num):
    if num == 0:
        return ALPHABET[0]
    s = []
    while num:
        num, rem = divmod(num, 62)
        s.append(ALPHABET[rem])
    return ''.join(reversed(s))
\`\`\`

### Shortening Flow (Pseudo)
\`\`\`text
POST /shorten
1. Validate input
2. If custom alias:
       insert into DB with constraint
3. Else:
       id = next_snowflake_id()
       code = base62(id)
       save(code, original_url)
4. Return short URL
\`\`\`

### Redirect Flow (Pseudo)
\`\`\`text
GET /{code}
- Check CDN
- Check Redis
- If not present ‚Üí fetch from DB ‚Üí set Redis
- Redirect
- Fire async analytics event
\`\`\`

## 16. Final Architecture Summary

A production-grade URL shortener must have:

- CDN caching ‚Üí fastest redirect
- Redis caching ‚Üí protect DB
- Global load balancing
- Stateless app servers
- Distributed ID + base62
- NoSQL or sharded SQL store
- Separate analytics pipeline
- Heavy rate-limiting

## Conclusion

A URL shortener isn‚Äôt ‚Äújust a toy project.‚Äù
It‚Äôs a mini distributed system that touches:
Consistency, Caching, Sharding, Queueing, Observability, Distributed ID generation, Security, Hot key avoidance, Global latency optimization.
        `
    },
    {
        id: '3',
        title: 'Dynamic Programming vs. Recursion: A Deep Dive',
        description: 'Recursion is intuitive, but often inefficient due to repeated calculations. Dynamic Programming (DP) optimizes this by storing results.',
        type: 'blog',
        tags: ['Dynamic Programming', 'Recursion', 'DSA', 'Optimization'],
        date: 'Dec 05, 2023',
        readTime: '15 min read',
        author: 'CodeNinja',
        content: `
## Introduction
Dynamic Programming (DP) is often feared by developers, but it is simply an optimization over plain recursion. It ensures that a method doesn't take more time than necessary by storing the results of subproblems.

## Recursion: The "Top-Down" Intuition
Recursion solves a problem by breaking it down into smaller instances of the same problem.
**Example**: Fibonacci. \`F(n) = F(n-1) + F(n-2)\`.

\`\`\`python
def fib(n):
    if n <= 1: return n
    return fib(n-1) + fib(n-2)
\`\`\`
**Problem**: This has exponential time complexity **O(2^n)**. We recalculate \`fib(5)\` many times when calculating \`fib(100)\`.

## Dynamic Programming: The Fix
DP basically says: "If we've solved it once, don't solve it again."

### Approach 1: Memoization (Top-Down)
We use a cache (Map or Array) to store results.

\`\`\`python
cache = {}
def fib_memo(n):
    if n <= 1: return n
    if n in cache: return cache[n]
    
    result = fib_memo(n-1) + fib_memo(n-2)
    cache[n] = result
    return result
\`\`\`
**Complexity**: O(N).

### Approach 2: Tabulation (Bottom-Up)
We build the solution from the ground up, avoiding recursion overhead completely.

\`\`\`python
def fib_tab(n):
    if n <= 1: return n
    dp = [0] * (n + 1)
    dp[1] = 1
    
    for i in range(2, n + 1):
        dp[i] = dp[i-1] + dp[i-2]
    
    return dp[n]
\`\`\`

## Key Differences

| Feature | Recursion | DP (Memoization) | DP (Tabulation) |
|---------|-----------|------------------|-----------------|
| **Space** | Stack heavy | Stack + Cache | Cache only |
| **Speed** | Slow (Redundant) | Fast | Fast (No recursion overhead) |
| **Style** | Declarative | Optimized Declarative | Iterative |

## Conclusion
Mastering specific patterns like 1D DP (Climbing Stairs) and 2D DP (Knapsack) will make you a formidable problem solver.
        `
    },
    {
        id: '4',
        title: 'Graph traversal: a detailed guide ‚Äî BFS vs DFS (with code & examples)',
        description: 'Graph traversal is one of the fundamental topics in algorithms and data structures. A comprehensive guide explaining BFS and DFS with working code, step-by-step examples, complexity analysis, and real-world applications.',
        type: 'blog',
        tags: ['Graph Theory', 'BFS', 'DFS', 'DSA'],
        date: 'Jan 10, 2024',
        readTime: '20 min read',
        author: 'GraphGuru',
        content: `
# Graph traversal: a detailed guide ‚Äî BFS vs DFS (with code & examples)

Graph traversal is one of the fundamental topics in algorithms and data structures. In this blog-style guide I'll explain the two core traversal strategies ‚Äî Breadth-First Search (BFS) and Depth-First Search (DFS) ‚Äî show clear diagrams in text, provide step-by-step runs, give working code (Python and Java), discuss complexity, real use cases, variants, common pitfalls and practice problems.

## Quick overview

Graph traversal = visiting nodes (vertices) of a graph in some systematic way so every reachable vertex is visited (often exactly once).

Two canonical strategies:

**BFS (Breadth-First Search)**: visits nodes level by level ‚Äî uses a queue.

**DFS (Depth-First Search)**: explores as far as possible along a branch before backtracking ‚Äî uses recursion or an explicit stack.

Both work on directed or undirected graphs and can be implemented for graphs represented as adjacency lists or adjacency matrices. Adjacency lists are preferred for sparse graphs.

## Graph basics (short)

A graph G = (V, E) where V is set of vertices and E set of edges.

**Undirected**: edges (u, v) and (v, u) are same.

**Directed**: edges have direction u -> v.

**Representations**:

- Adjacency list: Map<Vertex, List<Vertex>> or List<List<Integer>>.
- Adjacency matrix: matrix[u][v] = 1 if edge exists.

For traversal we typically need:

- A visited set (or boolean array) to avoid revisiting nodes and infinite loops on cycles.
- A data structure to drive the order: queue for BFS, stack/recursion for DFS.

## Breadth-First Search (BFS)

### Intuition

BFS starts at a source node, visits all its neighbors first (distance 1), then neighbors' neighbors (distance 2), etc. If you think of the graph as layers measured by shortest path length (in unweighted graphs), BFS expands outward one layer at a time.

### When to use BFS

- Find shortest path (fewest edges) in an unweighted graph.
- Level-order traversal, minimum number of moves.
- Finding connected component sizes, shortest reach.
- In puzzles where every move has equal cost.

### Algorithm (high level)

1. Mark source s visited and enqueue s.
2. While queue not empty:
   - Dequeue u.
   - For each neighbor v of u:
     - If not visited, mark visited, record parent (if you need path), and enqueue v.

### Complexity

- **Time**: O(V + E) for adjacency list (each edge and vertex processed once).
- **Space**: O(V) for visited + queue + optional parent/distance arrays.

### Implementation

<!-- MULTILANG_START -->
\`\`\`python
from collections import deque

def bfs(adj, start):
    """
    adj: list of lists, adjacency list, adj[u] = [v1, v2, ...]
    start: start vertex (int)
    returns: order list of visited vertices, and parent array (for paths)
    """
    n = len(adj)
    visited = [False] * n
    parent = [-1] * n
    order = []
    q = deque()
    visited[start] = True
    q.append(start)

    while q:
        u = q.popleft()
        order.append(u)
        for v in adj[u]:
            if not visited[v]:
                visited[v] = True
                parent[v] = u
                q.append(v)
    return order, parent

# Example usage:
# Graph: 0 -> [1, 2], 1 -> [2], 2 -> [0, 3], 3 -> [3]
adj = [[1, 2], [2], [0, 3], [3]]
print(bfs(adj, 2))  # e.g., starting from node 2
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
import java.util.*;

public class BFS {
    public static Pair<List<Integer>, int[]> bfs(List<List<Integer>> adj, int start) {
        int n = adj.size();
        boolean[] visited = new boolean[n];
        int[] parent = new int[n];
        Arrays.fill(parent, -1);
        List<Integer> order = new ArrayList<>();
        Queue<Integer> q = new ArrayDeque<>();

        visited[start] = true;
        q.add(start);

        while (!q.isEmpty()) {
            int u = q.poll();
            order.add(u);
            for (int v : adj.get(u)) {
                if (!visited[v]) {
                    visited[v] = true;
                    parent[v] = u;
                    q.add(v);
                }
            }
        }
        return new Pair<>(order, parent);
    }
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
#include <vector>
#include <queue>
#include <utility>
using namespace std;

pair<vector<int>, vector<int>> bfs(vector<vector<int>>& adj, int start) {
    int n = adj.size();
    vector<bool> visited(n, false);
    vector<int> parent(n, -1);
    vector<int> order;
    queue<int> q;
    
    visited[start] = true;
    q.push(start);
    
    while (!q.empty()) {
        int u = q.front();
        q.pop();
        order.push_back(u);
        
        for (int v : adj[u]) {
            if (!visited[v]) {
                visited[v] = true;
                parent[v] = u;
                q.push(v);
            }
        }
    }
    
    return {order, parent};
}

// Example usage:
// vector<vector<int>> adj = {{1, 2}, {2}, {0, 3}, {3}};
// auto [order, parent] = bfs(adj, 2);
\`\`\`
<!-- MULTILANG_END -->


\`\`\`java
import java.util.*;

public class BFS {
    public static Pair<List<Integer>, int[]> bfs(List<List<Integer>> adj, int start) {
        int n = adj.size();
        boolean[] visited = new boolean[n];
        int[] parent = new int[n];
        Arrays.fill(parent, -1);
        List<Integer> order = new ArrayList<>();
        Queue<Integer> q = new ArrayDeque<>();

        visited[start] = true;
        q.add(start);

        while (!q.isEmpty()) {
            int u = q.poll();
            order.add(u);
            for (int v : adj.get(u)) {
                if (!visited[v]) {
                    visited[v] = true;
                    parent[v] = u;
                    q.add(v);
                }
            }
        }
        return new Pair<>(order, parent); // assume Pair class or return custom object
    }
}
\`\`\`

### Step-by-step example (text)

Graph (undirected) adjacency lists:

- 0: [1, 2]
- 1: [0, 3]
- 2: [0, 3]
- 3: [1, 2, 4]
- 4: [3]

Start at 0:

1. Queue initially: [0], visited {0}
2. Pop 0 ‚Üí visit neighbors 1,2 ‚Üí enqueue: [1,2], visited {0,1,2}
3. Pop 1 ‚Üí neighbors 0(already),3 ‚Üí enqueue 3: [2,3], visited {0,1,2,3}
4. Pop 2 ‚Üí neighbors 0,3 (both visited) ‚Üí queue [3]
5. Pop 3 ‚Üí neighbor 4 ‚Üí enqueue ‚Üí [4], visited {0,1,2,3,4}
6. Pop 4 ‚Üí neighbors visited ‚Üí done

**Order**: 0,1,2,3,4

## Depth-First Search (DFS)

### Intuition

DFS starts at the source and goes deep into the graph following one neighbor, then another, until it can't go further; then it backtracks. Think of exploring a maze by always taking one unexplored path until you hit a dead end, then stepping back.

### When to use DFS

- When you need to explore all nodes/paths (e.g., search space traversal).
- Topological sort (with post-order timestamps) in DAGs.
- Detect cycles (directed/undirected).
- Strongly connected components (Kosaraju, Tarjan).
- Path-finding where you don't necessarily want shortest path and recursion suits problem.

### Complexity

- **Time**: O(V + E) for adjacency list.
- **Space**: O(V) for visited plus recursion stack (worst-case O(V)).

### Variants

- **Recursive DFS**: simplest to write.
- **Iterative DFS using explicit stack**: avoids recursion stack depth limits and can produce different visit orders.

### Implementation

#### Recursive DFS

<!-- MULTILANG_START -->
\`\`\`python
def dfs_recursive(adj, start, visited=None, parent=None, order=None):
    if visited is None:
        n = len(adj)
        visited = [False] * n
        parent = [-1] * n
        order = []
    visited[start] = True
    order.append(start)
    for v in adj[start]:
        if not visited[v]:
            parent[v] = start
            dfs_recursive(adj, v, visited, parent, order)
    return order, parent

# Example usage:
adj = [[1,2], [0,3], [0,3], [1,2]]
print(dfs_recursive(adj, 0))
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
import java.util.*;

public class DFS {
    public static void dfsRecursive(List<List<Integer>> adj, int u, boolean[] visited, int[] parent, List<Integer> order) {
        visited[u] = true;
        order.add(u);
        for (int v : adj.get(u)) {
            if (!visited[v]) {
                parent[v] = u;
                dfsRecursive(adj, v, visited, parent, order);
            }
        }
    }

    public static Pair<List<Integer>, int[]> dfs(List<List<Integer>> adj, int start) {
        int n = adj.size();
        boolean[] visited = new boolean[n];
        int[] parent = new int[n];
        Arrays.fill(parent, -1);
        List<Integer> order = new ArrayList<>();
        dfsRecursive(adj, start, visited, parent, order);
        return new Pair<>(order, parent);
    }
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
#include <vector>
using namespace std;

void dfsRecursive(vector<vector<int>>& adj, int u, vector<bool>& visited, 
                  vector<int>& parent, vector<int>& order) {
    visited[u] = true;
    order.push_back(u);
    for (int v : adj[u]) {
        if (!visited[v]) {
            parent[v] = u;
            dfsRecursive(adj, v, visited, parent, order);
        }
    }
}

pair<vector<int>, vector<int>> dfs(vector<vector<int>>& adj, int start) {
    int n = adj.size();
    vector<bool> visited(n, false);
    vector<int> parent(n, -1);
    vector<int> order;
    dfsRecursive(adj, start, visited, parent, order);
    return {order, parent};
}

// Example usage:
// vector<vector<int>> adj = {{1,2}, {0,3}, {0,3}, {1,2}};
// auto [order, parent] = dfs(adj, 0);
\`\`\`
<!-- MULTILANG_END -->

#### Iterative DFS (explicit stack)

<!-- MULTILANG_START -->
\`\`\`python
def dfs_iterative(adj, start):
    n = len(adj)
    visited = [False] * n
    parent = [-1] * n
    order = []
    stack = [start]

    while stack:
        u = stack.pop()
        if not visited[u]:
            visited[u] = True
            order.append(u)
            # push neighbors ‚Äî to mimic recursive order, push in reverse
            for v in reversed(adj[u]):
                if not visited[v]:
                    parent[v] = u
                    stack.append(v)
    return order, parent
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
import java.util.*;

public class DFSIterative {
    public static Pair<List<Integer>, int[]> dfs(List<List<Integer>> adj, int start) {
        int n = adj.size();
        boolean[] visited = new boolean[n];
        int[] parent = new int[n];
        Arrays.fill(parent, -1);
        List<Integer> order = new ArrayList<>();
        Stack<Integer> stack = new Stack<>();
        stack.push(start);

        while (!stack.isEmpty()) {
            int u = stack.pop();
            if (!visited[u]) {
                visited[u] = true;
                order.add(u);
                // Push neighbors in reverse to mimic recursive order
                List<Integer> neighbors = adj.get(u);
                for (int i = neighbors.size() - 1; i >= 0; i--) {
                    int v = neighbors.get(i);
                    if (!visited[v]) {
                        parent[v] = u;
                        stack.push(v);
                    }
                }
            }
        }
        return new Pair<>(order, parent);
    }
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
#include <vector>
#include <stack>
#include <algorithm>
using namespace std;

pair<vector<int>, vector<int>> dfs_iterative(vector<vector<int>>& adj, int start) {
    int n = adj.size();
    vector<bool> visited(n, false);
    vector<int> parent(n, -1);
    vector<int> order;
    stack<int> st;
    st.push(start);

    while (!st.empty()) {
        int u = st.top();
        st.pop();
        if (!visited[u]) {
            visited[u] = true;
            order.push_back(u);
            // Push neighbors in reverse to mimic recursive order
            for (int i = adj[u].size() - 1; i >= 0; i--) {
                int v = adj[u][i];
                if (!visited[v]) {
                    parent[v] = u;
                    st.push(v);
                }
            }
        }
    }
    return {order, parent};
}
\`\`\`
<!-- MULTILANG_END -->

### DFS example run (text)

Using the same graph from BFS example:

Start at 0

Visit 0 ‚Üí pick neighbor 1 ‚Üí visit 1 ‚Üí pick neighbor 3 ‚Üí visit 3 ‚Üí pick neighbor 2 ‚Üí visit 2 ‚Üí backtrack ‚Üí 4 might be visited depending on neighbor order...

**Order** depends on neighbor ordering; a valid DFS order: 0,1,3,2,4 (or 0,2,3,1,4) depending on adjacency order.

## BFS vs DFS ‚Äî side-by-side

| Aspect | BFS | DFS |
|--------|-----|-----|
| Order | Level by level (increasing distance) | Deep first (explore path then backtrack) |
| Data structure | Queue | Recursion stack / explicit Stack |
| Shortest path (unweighted) | Yes | Not guaranteed |
| Space (worst case) | O(V) (queue may hold many nodes) | O(V) (recursion/stack can be large) |
| Good for | Shortest paths, levels, closest node | Topological sort, cycle detection, path enumeration, SCC |
| Typical use-cases | Social networks, shortest steps, BFS-tree | Maze solving, backtracking, graph/component structure |

## Practical use cases & examples

### BFS

- Shortest path in an unweighted graph (e.g., minimum number of moves in a board game).
- Finding nodes at distance k.
- Solving the classic "shortest path in grid" (0/1 BFS variation for weights 0/1).

### DFS

- Topological sort (use reverse postorder).
- Detect cycles in directed graphs (coloring: white/gray/black).
- Finding connected components.
- Finding bridges and articulation points (using DFS timestamps / low-link).
- Solving puzzles where you must explore all configurations (backtracking).

## Variants & important patterns

- **Bidirectional BFS**: run BFS from both source and target; meet in middle ‚Äî often reduces complexity dramatically.
- **Iterative deepening DFS (IDDFS)**: repeated DFS with increasing depth limit; combines DFS memory-efficiency with BFS optimality in unweighted trees.
- **BFS with distance & parent arrays**: store distances (dist[v] = dist[u] + 1) and parents to reconstruct shortest path.
- **DFS timestamping**: record tin[u] and tout[u] for ancestor checks, used in many graph algorithms.

## Common pitfalls & tips

- **Forget visited** ‚Üí infinite loops in graphs with cycles.
- **Using recursion for very deep graphs** ‚Üí may cause stack overflow; use iterative stack if depth can be large.
- **Wrong graph representation** ‚Üí adjacency matrix can be expensive (O(V¬≤)) for large sparse graphs.
- **Order matters** ‚Äî traversal order depends on neighbor ordering; tests may expect specific orders.
- **Directed vs undirected** ‚Äî remember to add edges appropriately (two-way for undirected).
- **Reconstructing path** ‚Äî store parent pointers during BFS/DFS to build actual path from start to target.

## Example: shortest path using BFS (Python) ‚Äî reconstruct path

\`\`\`python
from collections import deque

def bfs_shortest_path(adj, start, target):
    n = len(adj)
    visited = [False] * n
    parent = [-1] * n
    q = deque([start])
    visited[start] = True

    while q:
        u = q.popleft()
        if u == target:
            break
        for v in adj[u]:
            if not visited[v]:
                visited[v] = True
                parent[v] = u
                q.append(v)

    if not visited[target]:
        return None  # no path

    # reconstruct path
    path = []
    cur = target
    while cur != -1:
        path.append(cur)
        cur = parent[cur]
    path.reverse()
    return path

# Example:
adj = [[1,2], [0,3], [0,3], [1,2,4], [3]]
print(bfs_shortest_path(adj, 0, 4))  # e.g., output [0,1,3,4] or [0,2,3,4] depending on adjacency
\`\`\`

## Exercises (try them)

1. Given a grid with obstacles, find the shortest path from start to target using BFS.
2. Use DFS to check if a directed graph has a cycle.
3. Implement bidirectional BFS and compare node expansions vs standard BFS on long paths.
4. Compute connected components in an undirected graph and output sizes.
5. Use DFS to perform topological sort on a DAG.

## Final notes and recommendations

- Use **BFS** when you need the shortest path in an unweighted graph or want level information.
- Use **DFS** for exploring deep structure, when you need postorder (topological sort), or when you need to enumerate possible solutions (backtracking).
- For large graphs prefer **adjacency list**.
- Always maintain a **visited structure** and be mindful of stack vs queue memory characteristics.
- Implement both **iterative and recursive versions** to be comfortable with recursion limits and explicit stacks.
        `
    },
    {
        id: '5',
        title: 'Understanding React Fiber Architecture',
        description: 'React Fiber was a complete rewrite of React\'s core reconciliation algorithm.',
        type: 'blog',
        tags: ['React', 'Frontend', 'Architecture'],
        date: 'Feb 15, 2024',
        readTime: '14 min read',
        author: 'ReactCore',
        content: `
## Introduction
In 2017, React introduced **Fiber**, a complete rewrite of its reconciliation algorithm that enables React to pause, resume, and prioritize rendering work.

## Benefits of Fiber
1. **Interruptible Rendering**: Pause and resume work
2. **Priority-Based Updates**: Urgent updates go first
3. **Better Error Handling**: Error boundaries work across async boundaries
4. **Concurrent Features**: Suspense, useTransition, useDeferredValue

## Conclusion
React Fiber transformed React from a simple library to a sophisticated rendering engine capable of handling complex UIs.
        `
    },
    {
        id: '6',
        title: 'Top 10 Sorting Algorithms Every Developer Should Know',
        description: 'From the simplicity of Bubble Sort to the efficiency of Quick Sort and Merge Sort.',
        type: 'blog',
        tags: ['Sorting', 'Algorithms', 'DSA', 'Computer Science'],
        date: 'Mar 01, 2024',
        readTime: '11 min read',
        author: 'AlgoMaster',
        content: `
# Top 10 Sorting Algorithms ‚Äî A Practical Blog with Code & Examples

Nice ‚Äî you wanted a blog-style walkthrough plus runnable code for each algorithm. Below you‚Äôll find a short, clear explanation of what it is, when to use it, time/space complexity, and implementations in **Python**, **Java**, **C++**, and **JavaScript**.

---

## 1. Bubble Sort

- **What**: Repeatedly swaps adjacent elements if they‚Äôre in the wrong order.
- **When**: Mostly educational ‚Äî tiny arrays or to demonstrate swapping/iteration.
- **Complexity**: O(n¬≤) time, O(1) space.

<!-- MULTILANG_START -->
\`\`\`python
def bubble_sort(arr):
    a = arr.copy()
    n = len(a)
    for i in range(n):
        swapped = False
        for j in range(0, n - i - 1):
            if a[j] > a[j+1]:
                a[j], a[j+1] = a[j+1], a[j]
                swapped = True
        if not swapped:
            break
    return a

# Example
arr = [5, 2, 9, 1, 5, 6]
print("Bubble:", bubble_sort(arr))
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
import java.util.Arrays;

public class BubbleSort {
    public static void bubbleSort(int[] arr) {
        int n = arr.length;
        boolean swapped;
        for (int i = 0; i < n - 1; i++) {
            swapped = false;
            for (int j = 0; j < n - i - 1; j++) {
                if (arr[j] > arr[j + 1]) {
                    // swap arr[j] and arr[j+1]
                    int temp = arr[j];
                    arr[j] = arr[j + 1];
                    arr[j + 1] = temp;
                    swapped = true;
                }
            }
            if (!swapped) break;
        }
    }

    public static void main(String[] args) {
        int[] arr = {5, 2, 9, 1, 5, 6};
        bubbleSort(arr);
        System.out.println("Bubble: " + Arrays.toString(arr));
    }
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
#include <iostream>
#include <vector>
#include <algorithm>

void bubbleSort(std::vector<int>& arr) {
    int n = arr.size();
    bool swapped;
    for (int i = 0; i < n - 1; i++) {
        swapped = false;
        for (int j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                std::swap(arr[j], arr[j + 1]);
                swapped = true;
            }
        }
        if (!swapped) break;
    }
}

int main() {
    std::vector<int> arr = {5, 2, 9, 1, 5, 6};
    bubbleSort(arr);
    std::cout << "Bubble: ";
    for(int x : arr) std::cout << x << " ";
    std::cout << std::endl;
    return 0;
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`javascript
function bubbleSort(arr) {
    let a = [...arr]; // clone
    let n = a.length;
    for (let i = 0; i < n; i++) {
        let swapped = false;
        for (let j = 0; j < n - i - 1; j++) {
            if (a[j] > a[j+1]) {
                [a[j], a[j+1]] = [a[j+1], a[j]];
                swapped = true;
            }
        }
        if (!swapped) break;
    }
    return a;
}

// Example
const arr = [5, 2, 9, 1, 5, 6];
console.log("Bubble:", bubbleSort(arr));
\`\`\`
<!-- MULTILANG_END -->

## 2. Selection Sort

- **What**: Repeatedly selects the minimum element and places it at the front.
- **When**: Educational, tiny arrays, or memory constrained where swaps are few.
- **Complexity**: O(n¬≤) time, O(1) space.

<!-- MULTILANG_START -->
\`\`\`python
def selection_sort(arr):
    a = arr.copy()
    n = len(a)
    for i in range(n):
        min_idx = i
        for j in range(i+1, n):
            if a[j] < a[min_idx]:
                min_idx = j
        a[i], a[min_idx] = a[min_idx], a[i]
    return a

# Example
arr = [64, 25, 12, 22, 11]
print("Selection:", selection_sort(arr))
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
import java.util.Arrays;

public class SelectionSort {
    public static void selectionSort(int[] arr) {
        int n = arr.length;
        for (int i = 0; i < n - 1; i++) {
            int min_idx = i;
            for (int j = i + 1; j < n; j++)
                if (arr[j] < arr[min_idx])
                    min_idx = j;
            
            int temp = arr[min_idx];
            arr[min_idx] = arr[i];
            arr[i] = temp;
        }
    }

    public static void main(String[] args) {
        int[] arr = {64, 25, 12, 22, 11};
        selectionSort(arr);
        System.out.println("Selection: " + Arrays.toString(arr));
    }
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
#include <iostream>
#include <vector>
#include <algorithm>

void selectionSort(std::vector<int>& arr) {
    int n = arr.size();
    for (int i = 0; i < n - 1; i++) {
        int min_idx = i;
        for (int j = i + 1; j < n; j++)
            if (arr[j] < arr[min_idx])
                min_idx = j;
        
        std::swap(arr[min_idx], arr[i]);
    }
}

int main() {
    std::vector<int> arr = {64, 25, 12, 22, 11};
    selectionSort(arr);
    std::cout << "Selection: ";
    for(int x : arr) std::cout << x << " ";
    std::cout << std::endl;
    return 0;
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`javascript
function selectionSort(arr) {
    let a = [...arr];
    let n = a.length;
    for (let i = 0; i < n; i++) {
        let minIdx = i;
        for (let j = i + 1; j < n; j++) {
            if (a[j] < a[minIdx]) {
                minIdx = j;
            }
        }
        [a[i], a[minIdx]] = [a[minIdx], a[i]];
    }
    return a;
}

// Example
const arr = [64, 25, 12, 22, 11];
console.log("Selection:", selectionSort(arr));
\`\`\`
<!-- MULTILANG_END -->

## 3. Insertion Sort

- **What**: Builds the sorted array one element at a time by inserting into the correct position.
- **When**: Small arrays, nearly-sorted arrays, or as inner sort for hybrids.
- **Complexity**: O(n¬≤) worst, ~O(n) for nearly-sorted; O(1) extra space.

<!-- MULTILANG_START -->
\`\`\`python
def insertion_sort(arr):
    a = arr.copy()
    for i in range(1, len(a)):
        key = a[i]
        j = i - 1
        while j >= 0 and a[j] > key:
            a[j+1] = a[j]
            j -= 1
        a[j+1] = key
    return a

# Example
arr = [12, 11, 13, 5, 6]
print("Insertion:", insertion_sort(arr))
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
import java.util.Arrays;

public class InsertionSort {
    public static void insertionSort(int[] arr) {
        int n = arr.length;
        for (int i = 1; i < n; ++i) {
            int key = arr[i];
            int j = i - 1;
            while (j >= 0 && arr[j] > key) {
                arr[j + 1] = arr[j];
                j = j - 1;
            }
            arr[j + 1] = key;
        }
    }

    public static void main(String[] args) {
        int[] arr = {12, 11, 13, 5, 6};
        insertionSort(arr);
        System.out.println("Insertion: " + Arrays.toString(arr));
    }
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
#include <iostream>
#include <vector>

void insertionSort(std::vector<int>& arr) {
    int n = arr.size();
    for (int i = 1; i < n; i++) {
        int key = arr[i];
        int j = i - 1;
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j = j - 1;
        }
        arr[j + 1] = key;
    }
}

int main() {
    std::vector<int> arr = {12, 11, 13, 5, 6};
    insertionSort(arr);
    std::cout << "Insertion: ";
    for(int x : arr) std::cout << x << " ";
    std::cout << std::endl;
    return 0;
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`javascript
function insertionSort(arr) {
    let a = [...arr];
    for (let i = 1; i < a.length; i++) {
        let key = a[i];
        let j = i - 1;
        while (j >= 0 && a[j] > key) {
            a[j + 1] = a[j];
            j--;
        }
        a[j + 1] = key;
    }
    return a;
}

// Example
const arr = [12, 11, 13, 5, 6];
console.log("Insertion:", insertionSort(arr));
\`\`\`
<!-- MULTILANG_END -->

## 4. Merge Sort

- **What**: Divide-and-conquer ‚Äî split, sort halves, merge. Stable. Great for linked lists & external sorting.
- **When**: Large arrays, stable sort required, external sorting.
- **Complexity**: O(n log n) time, O(n) extra space.

<!-- MULTILANG_START -->
\`\`\`python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])
    i = j = 0
    merged = []
    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            merged.append(left[i]); i += 1
        else:
            merged.append(right[j]); j += 1
    merged.extend(left[i:])
    merged.extend(right[j:])
    return merged

# Example
arr = [38, 27, 43, 3, 9, 82, 10]
print("Merge:", merge_sort(arr))
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
import java.util.Arrays;

public class MergeSort {
    public static void merge(int[] arr, int l, int m, int r) {
        int n1 = m - l + 1;
        int n2 = r - m;
        int[] L = new int[n1];
        int[] R = new int[n2];

        for (int i = 0; i < n1; ++i) L[i] = arr[l + i];
        for (int j = 0; j < n2; ++j) R[j] = arr[m + 1 + j];

        int i = 0, j = 0, k = l;
        while (i < n1 && j < n2) {
            if (L[i] <= R[j]) arr[k++] = L[i++];
            else arr[k++] = R[j++];
        }

        while (i < n1) arr[k++] = L[i++];
        while (j < n2) arr[k++] = R[j++];
    }

    public static void sort(int[] arr, int l, int r) {
        if (l < r) {
            int m = l + (r - l) / 2;
            sort(arr, l, m);
            sort(arr, m + 1, r);
            merge(arr, l, m, r);
        }
    }

    public static void main(String[] args) {
        int[] arr = {38, 27, 43, 3, 9, 82, 10};
        sort(arr, 0, arr.length - 1);
        System.out.println("Merge: " + Arrays.toString(arr));
    }
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
#include <iostream>
#include <vector>

void merge(std::vector<int>& arr, int l, int m, int r) {
    int n1 = m - l + 1;
    int n2 = r - m;
    std::vector<int> L(n1), R(n2);
    
    for(int i = 0; i < n1; i++) L[i] = arr[l + i];
    for(int j = 0; j < n2; j++) R[j] = arr[m + 1 + j];
    
    int i = 0, j = 0, k = l;
    while (i < n1 && j < n2) {
        if (L[i] <= R[j]) arr[k++] = L[i++];
        else arr[k++] = R[j++];
    }
    while (i < n1) arr[k++] = L[i++];
    while (j < n2) arr[k++] = R[j++];
}

void mergeSort(std::vector<int>& arr, int l, int r) {
    if(l >= r) return;
    int m = l + (r-l)/2;
    mergeSort(arr, l, m);
    mergeSort(arr, m+1, r);
    merge(arr, l, m, r);
}

int main() {
    std::vector<int> arr = {38, 27, 43, 3, 9, 82, 10};
    mergeSort(arr, 0, arr.size()-1);
    std::cout << "Merge: ";
    for(int x : arr) std::cout << x << " ";
    std::cout << std::endl;
    return 0;
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`javascript
function mergeSort(arr) {
    if (arr.length <= 1) return arr;
    
    const mid = Math.floor(arr.length / 2);
    const left = mergeSort(arr.slice(0, mid));
    const right = mergeSort(arr.slice(mid));
    
    let result = [], i = 0, j = 0;
    while (i < left.length && j < right.length) {
        if (left[i] < right[j]) result.push(left[i++]);
        else result.push(right[j++]);
    }
    return result.concat(left.slice(i)).concat(right.slice(j));
}

const arr = [38, 27, 43, 3, 9, 82, 10];
console.log("Merge:", mergeSort(arr));
\`\`\`
<!-- MULTILANG_END -->

## 5. Quick Sort

- **What**: Partition-based divide-and-conquer. Extremely fast in practice.
- **When**: General-purpose when average-case speed matters; choose randomized pivot for safety.
- **Complexity**: Avg O(n log n), Worst O(n¬≤) (bad pivot); O(log n) average recursion space.

<!-- MULTILANG_START -->
\`\`\`python
import random
def quick_sort(arr):
    a = arr.copy()
    def _qs(l, r):
        if l < r:
            p = random.randint(l, r)
            a[p], a[r] = a[r], a[p]  # random pivot
            pivot = a[r]
            i = l
            for j in range(l, r):
                if a[j] <= pivot:
                    a[i], a[j] = a[j], a[i]
                    i += 1
            a[i], a[r] = a[r], a[i]
            _qs(l, i-1)
            _qs(i+1, r)
    _qs(0, len(a)-1)
    return a

# Example
arr = [10, 7, 8, 9, 1, 5]
print("Quick:", quick_sort(arr))
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
import java.util.Arrays;
import java.util.Random;

public class QuickSort {
    static Random rand = new Random();

    static int partition(int[] arr, int low, int high) {
        int randomPivot = rand.nextInt(high - low + 1) + low;
        int temp = arr[randomPivot]; 
        arr[randomPivot] = arr[high]; 
        arr[high] = temp;

        int pivot = arr[high]; 
        int i = (low - 1); 
        for (int j = low; j < high; j++) {
            if (arr[j] <= pivot) {
                i++;
                temp = arr[i];
                arr[i] = arr[j];
                arr[j] = temp;
            }
        }
        temp = arr[i + 1];
        arr[i + 1] = arr[high];
        arr[high] = temp;
        return i + 1;
    }

    static void sort(int[] arr, int low, int high) {
        if (low < high) {
            int pi = partition(arr, low, high);
            sort(arr, low, pi - 1);
            sort(arr, pi + 1, high);
        }
    }

    public static void main(String[] args) {
        int[] arr = {10, 7, 8, 9, 1, 5};
        sort(arr, 0, arr.length - 1);
        System.out.println("Quick: " + Arrays.toString(arr));
    }
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
#include <iostream>
#include <vector>
#include <cstdlib>
#include <algorithm>

int partition(std::vector<int>& arr, int low, int high) {
    int random = low + rand() % (high - low + 1);
    std::swap(arr[random], arr[high]);
    int pivot = arr[high];
    int i = (low - 1);
  
    for (int j = low; j <= high - 1; j++) {
        if (arr[j] <= pivot) {
            i++;
            std::swap(arr[i], arr[j]);
        }
    }
    std::swap(arr[i + 1], arr[high]);
    return (i + 1);
}

void quickSort(std::vector<int>& arr, int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high);
        quickSort(arr, low, pi - 1);
        quickSort(arr, pi + 1, high);
    }
}

int main() {
    std::vector<int> arr = {10, 7, 8, 9, 1, 5};
    quickSort(arr, 0, arr.size() - 1);
    std::cout << "Quick: ";
    for(int x : arr) std::cout << x << " ";
    std::cout << std::endl;
    return 0;
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`javascript
function quickSort(arr) {
    if (arr.length <= 1) return arr;
    
    const pivot = arr[arr.length - 1];
    const left = [];
    const right = [];
    
    for(let i = 0; i < arr.length - 1; i++) {
        if(arr[i] < pivot) left.push(arr[i]);
        else right.push(arr[i]);
    }
    
    return [...quickSort(left), pivot, ...quickSort(right)];
}

const arr = [10, 7, 8, 9, 1, 5];
console.log("Quick:", quickSort(arr));
\`\`\`
<!-- MULTILANG_END -->

## 6. Heap Sort

- **What**: Uses a binary heap to repeatedly extract max (or min) and build sorted array. In-place, guaranteed O(n log n).
- **When**: When you need worst-case guarantees and O(1) extra space (if implemented in-place).
- **Complexity**: O(n log n) time, O(1) extra space (in-place variant).

<!-- MULTILANG_START -->
\`\`\`python
def heap_sort(arr):
    a = arr.copy()
    n = len(a)
    # heapify
    def heapify(n, i):
        largest = i
        l = 2*i + 1
        r = 2*i + 2
        if l < n and a[l] > a[largest]: largest = l
        if r < n and a[r] > a[largest]: largest = r
        if largest != i:
            a[i], a[largest] = a[largest], a[i]
            heapify(n, largest)
    for i in range(n//2 - 1, -1, -1):
        heapify(n, i)
    # extract
    for i in range(n-1, 0, -1):
        a[0], a[i] = a[i], a[0]
        heapify(i, 0)
    return a

# Example
arr = [12, 11, 13, 5, 6, 7]
print("Heap:", heap_sort(arr))
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
import java.util.Arrays;

public class HeapSort {
    public static void sort(int arr[]) {
        int n = arr.length;
        for (int i = n / 2 - 1; i >= 0; i--)
            heapify(arr, n, i);
        for (int i = n - 1; i > 0; i--) {
            int temp = arr[0];
            arr[0] = arr[i];
            arr[i] = temp;
            heapify(arr, i, 0);
        }
    }

    static void heapify(int arr[], int n, int i) {
        int largest = i;
        int l = 2 * i + 1;
        int r = 2 * i + 2;
        if (l < n && arr[l] > arr[largest]) largest = l;
        if (r < n && arr[r] > arr[largest]) largest = r;
        if (largest != i) {
            int swap = arr[i];
            arr[i] = arr[largest];
            arr[largest] = swap;
            heapify(arr, n, largest);
        }
    }

    public static void main(String args[]) {
        int arr[] = {12, 11, 13, 5, 6, 7};
        sort(arr);
        System.out.println("Heap: " + Arrays.toString(arr));
    }
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
#include <iostream>
#include <vector>
#include <algorithm>

void heapify(std::vector<int>& arr, int n, int i) {
    int largest = i;
    int l = 2 * i + 1;
    int r = 2 * i + 2;
    if (l < n && arr[l] > arr[largest]) largest = l;
    if (r < n && arr[r] > arr[largest]) largest = r;
    if (largest != i) {
        std::swap(arr[i], arr[largest]);
        heapify(arr, n, largest);
    }
}

void heapSort(std::vector<int>& arr) {
    int n = arr.size();
    for (int i = n / 2 - 1; i >= 0; i--)
        heapify(arr, n, i);
    for (int i = n - 1; i > 0; i--) {
        std::swap(arr[0], arr[i]);
        heapify(arr, i, 0);
    }
}

int main() {
    std::vector<int> arr = {12, 11, 13, 5, 6, 7};
    heapSort(arr);
    std::cout << "Heap: ";
    for(int x : arr) std::cout << x << " ";
    std::cout << std::endl;
    return 0;
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`javascript
function heapSort(arr) {
    let a = [...arr];
    let n = a.length;
    
    for (let i = Math.floor(n / 2) - 1; i >= 0; i--) heapify(a, n, i);
    for (let i = n - 1; i > 0; i--) {
        [a[0], a[i]] = [a[i], a[0]];
        heapify(a, i, 0);
    }
    return a;
}

function heapify(arr, n, i) {
    let largest = i;
    let l = 2 * i + 1;
    let r = 2 * i + 2;
    if (l < n && arr[l] > arr[largest]) largest = l;
    if (r < n && arr[r] > arr[largest]) largest = r;
    if (largest != i) {
        [arr[i], arr[largest]] = [arr[largest], arr[i]];
        heapify(arr, n, largest);
    }
}

const arr = [12, 11, 13, 5, 6, 7];
console.log("Heap:", heapSort(arr));
\`\`\`
<!-- MULTILANG_END -->

## 7. Counting Sort

- **What**: Non-comparison sort that counts occurrences of integers in a known range. Stable variant exists.
- **When**: Integers with small range k compared to n.
- **Complexity**: O(n + k) time, O(k) space.

<!-- MULTILANG_START -->
\`\`\`python
def counting_sort(arr, max_value=None):
    a = arr.copy()
    if not a:
        return a
    if max_value is None:
        max_value = max(a)
    min_value = min(a)
    range_of_vals = max_value - min_value + 1
    count = [0] * range_of_vals
    for num in a:
        count[num - min_value] += 1
    # stable output
    for i in range(1, len(count)):
        count[i] += count[i-1]
    output = [0]*len(a)
    for num in reversed(a):
        output[count[num - min_value] - 1] = num
        count[num - min_value] -= 1
    return output

# Example
arr = [4, 2, 2, 8, 3, 3, 1]
print("Counting:", counting_sort(arr))
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`java
import java.util.Arrays;

public class CountingSort {
    public static int[] countSort(int[] arr) {
        if (arr.length == 0) return arr;
        int max = Arrays.stream(arr).max().getAsInt();
        int min = Arrays.stream(arr).min().getAsInt();
        int range = max - min + 1;
        int count[] = new int[range];
        int output[] = new int[arr.length];
        
        for (int i = 0; i < arr.length; i++) count[arr[i] - min]++;
        for (int i = 1; i < count.length; i++) count[i] += count[i - 1];
        for (int i = arr.length - 1; i >= 0; i--) {
            output[count[arr[i] - min] - 1] = arr[i];
            count[arr[i] - min]--;
        }
        return output;
    }

    public static void main(String[] args) {
        int[] arr = {4, 2, 2, 8, 3, 3, 1};
        System.out.println("Counting: " + Arrays.toString(countSort(arr)));
    }
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`cpp
#include <iostream>
#include <vector>
#include <algorithm>

std::vector<int> countSort(std::vector<int>& arr) {
    if (arr.empty()) return arr;
    int max = *std::max_element(arr.begin(), arr.end());
    int min = *std::min_element(arr.begin(), arr.end());
    int range = max - min + 1;
    
    std::vector<int> count(range, 0), output(arr.size());
    for(int x : arr) count[x - min]++;
    for(int i = 1; i < range; i++) count[i] += count[i-1];
    for(int i = arr.size()-1; i >= 0; i--) {
        output[count[arr[i] - min] - 1] = arr[i];
        count[arr[i] - min]--;
    }
    return output;
}

int main() {
    std::vector<int> arr = {4, 2, 2, 8, 3, 3, 1};
    std::vector<int> res = countSort(arr);
    std::cout << "Counting: ";
    for(int x : res) std::cout << x << " ";
    std::cout << std::endl;
    return 0;
}
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`javascript
function countingSort(arr) {
    if (arr.length === 0) return arr;
    const min = Math.min(...arr);
    const max = Math.max(...arr);
    const range = max - min + 1;
    const count = new Array(range).fill(0);
    const output = new Array(arr.length);
    
    arr.forEach(num => count[num - min]++);
    for (let i = 1; i < len(count); i++) count[i] += count[i - 1];
    for (let i = arr.length - 1; i >= 0; i--) {
        output[count[arr[i] - min] - 1] = arr[i];
        count[arr[i] - min]--;
    }
    return output;
}

const arr = [4, 2, 2, 8, 3, 3, 1];
console.log("Counting:", countingSort(arr));
\`\`\`
<!-- MULTILANG_END -->

## 8. Radix Sort

- **What**: Sorts numbers digit-by-digit using stable sort (often counting sort) as subroutine. Beats comparison bound when digits small.
- **When**: Large lists of integers/strings where digit count (d) is manageable.
- **Complexity**: O(d * (n + k)), where d = digits, k = base.

<!-- MULTILANG_START -->
\`\`\`python
def radix_sort(arr):
    a = arr.copy()
    if not a:
        return a
    max_val = max(a)
    exp = 1
    def counting_for_exp(a, exp):
        n = len(a)
        out = [0]*n
        count = [0]*10
        for num in a:
            index = (num // exp) % 10
            count[index] += 1
        for i in range(1, 10):
            count[i] += count[i-1]
        for i in range(n-1, -1, -1):
            index = (a[i] // exp) % 10
            out[count[index]-1] = a[i]
            count[index] -= 1
        return out
    while max_val // exp > 0:
        a = counting_for_exp(a, exp)
        exp *= 10
    return a

# Example
arr = [170, 45, 75, 90, 802, 24, 2, 66]
print("Radix:", radix_sort(arr))
\`\`\`
<!-- LANG_DIVIDER -->
\`\`\`javascript
function radixSort(arr) {
    const maxNum = Math.max(...arr) * 10;
    let divisor = 10;
    while (divisor < maxNum) {
        let buckets = [...Array(10)].map(() => []);
        for (let num of arr) {
            buckets[Math.floor((num % divisor) / (divisor / 10))].push(num);
        }
        arr = [].concat.apply([], buckets);
        divisor *= 10;
    }
    return arr;
}
\`\`\`
<!-- MULTILANG_END -->

## 9. Bucket Sort

- **What**: Distribute elements into buckets, sort each bucket (often with insertion sort), then concatenate. Works best with uniform distribution.
- **When**: Floating-point numbers in [0,1) or data known to be uniformly distributed.
- **Complexity**: Avg O(n + k) ~ O(n), Worst O(n¬≤).

<!-- MULTILANG_START -->
\`\`\`python
def bucket_sort(arr, bucket_size=5):
    if not arr:
        return arr
    min_val, max_val = min(arr), max(arr)
    bucket_count = (max_val - min_val) // bucket_size + 1
    buckets = [[] for _ in range(bucket_count)]
    for num in arr:
        idx = (num - min_val) // bucket_size
        buckets[idx].append(num)
    # sort each bucket using insertion sort
    sorted_arr = []
    for b in buckets:
        for x in insertion_sort(b):  # reuse insertion_sort above
            sorted_arr.append(x)
    return sorted_arr

# Example
arr = [0.42, 0.32, 0.23, 0.52, 0.25, 0.47, 0.51]
# convert floats by scaling to ints or adapt bucket_size; below demonstrates floats directly
print("Bucket:", bucket_sort(arr, bucket_size=1))
\`\`\`
<!-- MULTILANG_END -->

## 10. TimSort

- **What**: Hybrid stable sort used by Python and Java (for objects). It detects runs (already-sorted segments), uses insertion sort for short runs, and merges them efficiently. Excellent in practice ‚Äî best worst-case guarantees similar to mergesort and excellent performance on partially-sorted data.
- **When**: Default choice in languages/libraries ‚Äî you rarely reimplement it. Use built-in sorted() or .sort().
- **Complexity**: O(n log n) worst, O(n) best when lots of runs / nearly sorted. Stable.

<!-- MULTILANG_START -->
\`\`\`python
# Use built-in Timsort in Python ‚Äî don't reimplement in production
arr = [5, 2, 3, 1, 4]
print("Timsort (built-in):", sorted(arr))

# Simple illustrative mini-timsort: detect runs, sort small runs by insertion, then merge pairs.
def mini_timsort(arr, run_threshold=32):
    a = arr.copy()
    n = len(a)
    # 1) find runs and extend to run_threshold by insertion
    runs = []
    i = 0
    while i < n:
        j = i + 1
        # detect increasing run
        while j < n and a[j-1] <= a[j]:
            j += 1
        run = a[i:j]
        # extend small runs to threshold using insertion sort on the segment
        if len(run) < run_threshold:
            seg_end = min(n, i+run_threshold)
            seg = a[i:seg_end]
            seg = insertion_sort(seg)
            a[i:seg_end] = seg
            runs.append((i, seg_end))
            i = seg_end
        else:
            runs.append((i, j))
            i = j
    # 2) merge runs pairwise (naive)
    sorted_arr = []
    for (s,e) in runs:
        sorted_arr = merge_sort(sorted_arr + a[s:e]) if sorted_arr else a[s:e]
    return sorted_arr
\`\`\`
<!-- MULTILANG_END -->

## Quick Comparison Table

| Algorithm | Time (Best) | Time (Avg) | Time (Worst) | Space | Stable? |
|-----------|-------------|------------|--------------|-------|---------|
| Bubble    | O(n)        | O(n¬≤)      | O(n¬≤)        | O(1)  | Yes     |
| Selection | O(n¬≤)       | O(n¬≤)      | O(n¬≤)        | O(1)  | No      |
| Insertion | O(n)        | O(n¬≤)      | O(n¬≤)        | O(1)  | Yes     |
| Merge     | O(n log n)  | O(n log n) | O(n log n)   | O(n)  | Yes     |
| Quick     | O(n log n)  | O(n log n) | O(n¬≤)        | O(log n) | No   |
| Heap      | O(n log n)  | O(n log n) | O(n log n)   | O(1)  | No      |
| Counting  | O(n+k)      | O(n+k)     | O(n+k)       | O(k)  | Yes     |
| Radix     | O(nk)       | O(nk)      | O(nk)        | O(n+k)| Yes     |
| TimSort   | O(n)        | O(n log n) | O(n log n)   | O(n)  | Yes     |
        `
    },
    {
        id: '7',
        title: 'A Guide to SQL Indexing and Query Optimization',
        description: 'Database performance often hinges on proper indexing.',
        type: 'blog',
        tags: ['SQL', 'Databases', 'DBMS', 'Performance'],
        date: 'Mar 20, 2024',
        readTime: '9 min read',
        author: 'DBAdmin',
        content: `
## Introduction
Database performance is critical for application scalability. Slow queries can bottleneck your entire system. The secret weapon? **Indexes**.

## What is an Index?
An index is a **data structure** that improves the speed of data retrieval operations on a database table.

### Search Complexity
- **Time**: O(log n) with B-Tree
- **Example**: For 1 million rows, B-Tree needs ~20 comparisons vs 1 million for full scan

## Conclusion
Proper indexing transforms a slow database into a blazing-fast one. Always profile your queries with EXPLAIN and monitor index usage.
        `
    },
    {
        id: '8',
        title: 'Introduction to Microservices Architecture',
        description: 'Monoliths are simple to start, but hard to scale. Microservices offer loose coupling.',
        type: 'blog',
        tags: ['Microservices', 'Architecture', 'DevOps', 'Backend'],
        date: 'Apr 05, 2024',
        readTime: '13 min read',
        author: 'CloudNative',
        content: `
## Introduction
As applications grow, the **monolithic architecture** becomes a bottleneck. Teams step on each other's toes, deployments are risky, and scaling becomes inefficient. Enter **Microservices**.

## Benefits
1. **Independent Deployment**: Update one service without touching others
2. **Technology Flexibility**: Use different tech stacks per service
3. **Scalability**: Scale only the services that need it
4. **Fault Isolation**: One service crashes, others continue
5. **Team Autonomy**: Small teams own services end-to-end

## Conclusion
Microservices are powerful but come with complexity. Start with a monolith, and migrate to microservices when you feel the pain.
        `
    },
    {
        id: '9',
        title: 'The Art of Clean Code: SOLID Principles',
        description: 'Writing code that works is easy; writing code that is maintainable is an art.',
        type: 'blog',
        tags: ['Clean Code', 'Best Practices', 'SOLID', 'Software Engineering'],
        date: 'Apr 22, 2024',
        readTime: '7 min read',
        author: 'CleanCoder',
        content: `
## Introduction
Any programmer can write code that a computer understands. Great programmers write code that **humans** can understand. The SOLID principles are five design principles that make software more maintainable and flexible.

## Summary

| Principle | Description |
|-----------|-------------|
| **S** - SRP | One class, one responsibility |
| **O** - OCP | Extend, don't modify |
| **L** - LSP | Subtypes must be substitutable |
| **I** - ISP | Small, focused interfaces |
| **D** - DIP | Depend on abstractions |

## Conclusion
SOLID principles are the foundation of clean, maintainable code. They take practice to internalize, but once you do, your code becomes a joy to work with.
        `
    },
    {
        id: '10',
        title: 'The Myth of Work-Life Balance',
        description: 'Why aiming for perfect balance is a trap, and how to manage energy instead of time.',
        type: 'blog',
        tags: ['Life', 'Productivity', 'Mental Health'],
        date: 'May 01, 2024',
        readTime: '6 min read',
        author: 'LifeHacker',
        content: `
# The Myth of Work-Life Balance

We often hear that we need "balance" between work and life, as if they are two weights on a scale. But this binary view is flawed.

## Energy vs. Time
Instead of trying to split your *hours* perfectly (8 hours work, 8 hours life), focus on your **energy**. You can spend 2 hours with family but be mentally exhausted, or 10 hours working and feel energized. 

## The Seasons of Life
There are times to sprint and times to rest. Accepting that some weeks will be work-heavy and others life-heavy removes the guilt of "imbalance".

## Practical Tips
- **Audit your energy**: What drains you? What fills you up?
- **Set boundaries, not schedules**: It's easier to say "no work after 7 PM" than "work exactly 40 hours".
- **Quality over Quantity**: Presence matters more than duration.
        `
    },
    {
        id: '11',
        title: 'Why You Should Write Daily',
        description: 'Writing is not just for writers. It is a tool for clarifying thoughts and debugging your mind.',
        type: 'blog',
        tags: ['Self Improvement', 'Writing', 'Communication'],
        date: 'May 05, 2024',
        readTime: '5 min read',
        author: 'Abhinay Tiwari',
        content: `
# Why You Should Write Daily

Writing is the clearest indicator of your thinking quality. If you can't write it down simply, you don't understand it well enough.

## Debugging Your Mind
Just as we debug code to find logic errors, writing "debugs" our thoughts. It forces us to slow down and structure abstract ideas into concrete sentences.

## The Feynman Technique
Richard Feynman was famous for explaining complex topics simply. Writing daily creates a repository of your knowledge, explaining things to your future self.

## How to Start
- **Morning Pages**: 3 pages of stream of consciousness first thing in the morning.
- **Tech Journal**: Write down what you learned technically today.
- **Public Learning**: Share small wins on Twitter or LinkedIn.
        `
    },
    {
        id: '12',
        title: 'Navigating Imposter Syndrome in Tech',
        description: 'Feeling like a fraud? You are not alone. Here is how to manage the feeling that you do not belong.',
        type: 'blog',
        tags: ['Career', 'Mental Health', 'Soft Skills'],
        date: 'May 10, 2024',
        readTime: '7 min read',
        author: 'SeniorDev',
        content: `
# Navigating Imposter Syndrome

Did you know that 70% of high achievers experience imposter syndrome? In tech, where tools change every week, it's easy to feel left behind.

## It Never Goes Away
The senior engineer you admire? They feel it too. They just got better at managing it. The goal isn't to eliminate the fear, but to act in spite of it.

## Reframing the Feeling
Instead of thinking "I don't know this, I'm a fraud," think "I don't know this *yet*, and I'm good at learning."

## Track Your Wins
Keep a "Hype Doc". Every time you solve a bug, ship a feature, or help a colleague, write it down. Read it when you feel small.
        `
    },
    {
        id: '13',
        title: 'The Power of Deep Work',
        description: 'In a distracted world, the ability to focus without distraction is a superpower.',
        type: 'blog',
        tags: ['Productivity', 'Focus', 'Career'],
        date: 'May 15, 2024',
        readTime: '8 min read',
        author: 'DeepThinker',
        content: `
# The Power of Deep Work

Cal Newport coined the term "Deep Work": professional activities performed in a state of distraction-free concentration that push your cognitive capabilities to their limit.

## Depth vs. Shallow
- **Shallow Work**: Emails, Slack, meetings. Low value, easy to replicate.
- **Deep Work**: Coding complex algorithms, writing documentation, designing systems. High value, hard to replicate.

## Strategies for Depth
1. **The Bimodal Philosophy**: Dedicate huge chunks (days) to deep work.
2. **Ritualize**: Have a specific desk, coffee, or music playlist that signals "it's time to focus".
3. **Quit Social Media**: Or at least, block it during work hours.
        `
    },
    {
        id: '14',
        title: 'Networking for Introverts',
        description: 'You do not need to be the loudest person in the room to build a meaningful network.',
        type: 'blog',
        tags: ['Career', 'Networking', 'Soft Skills'],
        date: 'May 20, 2024',
        readTime: '6 min read',
        author: 'QuietLeader',
        content: `
# Networking for Introverts

Networking often feels "slimy" or exhausting for introverts. But it doesn't have to be transactional.

## 1. Focus on One-on-One
Introverts thrive in deep conversation. Skip the huge mixer events and invite someone for a coffee (virtual or real).

## 2. Be a Helper
Networking is about giving, not taking. Ask "What are you working on?" and see if you can send a helpful link or intro.

## 3. Use Asynchronous Comms
Twitter/X, LinkedIn, and GitHub allow you to "network" by sharing your work without the drain of real-time social pressure.
        `
    },
    {
        id: '15',
        title: 'Minimalism in a Digital Age',
        description: 'Declutter your digital life to reclaim your attention and mental space.',
        type: 'blog',
        tags: ['Life', 'Minimalism', 'Digital Wellbeing'],
        date: 'May 25, 2024',
        readTime: '5 min read',
        author: 'Minimalist',
        content: `
# Minimalism in a Digital Age

We hoard digital artifacts‚Äîthousands of photos, hundreds of open tabs, endless unread emails. This digital clutter creates mental noise.

## The Digital Declutter
1. **Phone Notification Audit**: Turn off everything except calls and texts.
2. **Desktop Zero**: Clear your desktop files weekly.
3. **Inbox Zero**: It‚Äôs not about having 0 emails, but processing them so they don't linger as "to-do" ghosts.

## Intentional Usage
Use technology as a tool, not a pacifier. Pick up your phone only when you have a specific task in mind.
        `
    },
    {
        id: '16',
        title: 'Investing for Software Engineers',
        description: 'You earn a high salary, but are you building wealth? Basics of financial independence.',
        type: 'blog',
        tags: ['Finance', 'Career', 'Life'],
        date: 'May 30, 2024',
        readTime: '9 min read',
        author: 'FinTechGuy',
        content: `
# Investing for Software Engineers

Software engineering is one of the few careers that offers a realistic path to early financial independence (FIRE).

## The Golden Equation
**Wealth = (Income - Expenses) * Investment Return**

As an engineer, your *Income* is high. Don't let *Expenses* creep up to match it (Lifestyle Inflation).

## Where to Put Money?
1. **Emergency Fund**: 3-6 months expenses.
2. **Employer Match**: Free money (401k/RRSP).
3. **Index Funds**: The boring, winning strategy. S&P 500 or Total Market funds outperform most stock pickers.

*Disclaimer: Not financial advice.*
        `
    },
    {
        id: '17',
        title: 'Burnout: Recognition and Recovery',
        description: 'Burnout is not just being tired. It is a state of emotional, physical, and mental exhaustion.',
        type: 'blog',
        tags: ['Health', 'Career', 'Mental Health'],
        date: 'Jun 05, 2024',
        readTime: '8 min read',
        author: 'WellnessDev',
        content: `
# Burnout: Recognition and Recovery

Burnout creeps up on you. It starts with "just pushing through" a deadline and ends with apathy toward the job you once loved.

## Signs
- **Cynicism**: Feeling like nothing you do matters.
- **Detachment**: Pulling away from colleagues.
- **Inefficacy**: Feeling like you can't accomplish anything.

## Recovery
1. **Disconnect**: Truly unplug. No Slack on weekends.
2. **Sleep**: It's the foundation of mental repair.
3. **Seek Professional Help**: Therapy is for the mind what the gym is for the body.
        `
    },
    {
        id: '18',
        title: 'Understanding Critical Rendering Path',
        description: 'How browsers turn HTML, CSS, and JS into pixels on the screen. Optimizing for speed.',
        type: 'blog',
        tags: ['Web Performance', 'Browser Internals', 'Frontend'],
        date: 'Jun 10, 2024',
        readTime: '10 min read',
        author: 'PerformanceGuru',
        content: `
# Understanding Critical Rendering Path

To build fast sites, you must understand how the browser thinks.

## The Steps
1. **DOM Construction**: Parsing HTML into the Document Object Model.
2. **CSSOM Construction**: Parsing CSS into the CSS Object Model.
3. **Render Tree**: Combining DOM + CSSOM.
4. **Layout**: Calculating geometry (where elements go).
5. **Paint**: Filling in pixels.

## Optimizing
- **Minify Critical CSS**: Inline critical styles in the \`<head>\`.
- **Defer Non-Critical JS**: Use \`defer\` or \`async\` attributes on script tags.
- **Reduce DOM Depth**: Flat HTML renders faster.
        `
    },
    {
        id: '19',
        title: 'A Guide to Web Accessibility (a11y)',
        description: 'The web is for everyone. How to build inclusive applications that support screen readers and keyboard navigation.',
        type: 'blog',
        tags: ['Accessibility', 'Frontend', 'HTML'],
        date: 'Jun 15, 2024',
        readTime: '8 min read',
        author: 'A11yAdvocate',
        content: `
# A Guide to Web Accessibility (a11y)

Accessibility isn't a feature; it's a requirement.

## Semantic HTML
Use \`<button>\` for buttons, not \`divs\`. Semantic HTML gives you 80% of accessibility for free.

## ARIA Labels
Use \`aria-label\` only when there is no visible text (e.g., an icon button). Don't overuse ARIA; native HTML is always better.

## Keyboard Navigation
Can you use your site without a mouse? Tab through your newly built form. If you get stuck, it's broken.
        `
    },
    {
        id: '20',
        title: 'CSS Grid vs Flexbox: When to Use Which?',
        description: 'Grid is for layout, Flexbox is for alignment. A definitive guide on choosing the right tool.',
        type: 'blog',
        tags: ['CSS', 'Frontend', 'Design'],
        date: 'Jun 20, 2024',
        readTime: '7 min read',
        author: 'CSSWizard',
        content: `
# CSS Grid vs Flexbox

It's not "Grid OR Flexbox". It's "Grid AND Flexbox".

## Flexbox (1D)
Best for:
- Aligning items in a single row or column.
- Distributing space between items (navbar, buttons).

## Grid (2D)
Best for:
- Page layouts (Header, Sidebar, Main, Footer).
- Complex galleries where items need to span multiple rows/columns.

## Pro Tip
Use Grid for the macro layout of the page, and Flexbox for the micro layout components inside those grid cells.
        `
    },
    {
        id: '21',
        title: 'The Future of React: Server Components',
        description: 'React Server Components (RSC) shift the paradigm. Moving logic to the server for faster apps.',
        type: 'blog',
        tags: ['React', 'Next.js', 'Frontend'],
        date: 'Jun 25, 2024',
        readTime: '9 min read',
        author: 'ReactNewbie',
        content: `
# The Future of React: Server Components

Traditionally, React was client-side. You download a huge JS bundle, and the client renders everything.

## The RSC Shift
Server Components run **only** on the server.
- **Zero Bundle Size**: Dependencies used in RSCs don't go to the client.
- **Direct DB Access**: Query your database directly in your component.

## When to use Client Components?
Use \`"use client"\` when you need interactivity:
- \`onClick\` listeners
- \`useState\`, \`useEffect\`
- Browser APIs (\`window\`, \`localStorage\`)
        `
    },
    {
        id: '22',
        title: 'Optimizing Web Performance Vitals',
        description: 'Deep dive into Core Web Vitals: LCP, CLS, and INP. How to measure and improve them.',
        type: 'blog',
        tags: ['Performance', 'SEO', 'Web'],
        date: 'Jun 30, 2024',
        readTime: '11 min read',
        author: 'SpeedDemon',
        content: `
# Optimizing Web Performance Vitals

Google ranks your site based on User Experience, measured by Core Web Vitals.

## LCP (Largest Contentful Paint)
- **Goal**: < 2.5s
- **Fix**: Optimize hero images, use a CDN, preload critical assets.

## CLS (Cumulative Layout Shift)
- **Goal**: < 0.1
- **Fix**: Set explicit \`width\` and \`height\` on images/videos. Don't inject content above existing content.

## INP (Interaction to Next Paint)
- **Goal**: < 200ms
- **Fix**: Break up long tasks in JS, optimize event handlers.
        `
    },
    {
        id: '23',
        title: 'SEO Best Practices for Developers',
        description: 'SEO is not just marketing. Technical SEO ensures your content is indexable and rankable.',
        type: 'blog',
        tags: ['SEO', 'Marketing', 'Web'],
        date: 'Jul 05, 2024',
        readTime: '6 min read',
        author: 'GrowthEng',
        content: `
# SEO Best Practices for Developers

You can build the best app, but if Google can't find it, it doesn't exist.

## 1. Meta Tags
- \`title\`: distinctive and descriptive.
- \`description\`: the ad copy for your link.
- \`og:image\`: for social sharing.

## 2. SSR vs CSR
Search/Social bots struggle with pure Client-Side Rendering (CSR). Use SSR (Next.js) or SSG for public pages.

## 3. Structured Data (JSON-LD)
Feed Google structured info (Product price, Review rating) so it can display "Rich Snippets".
        `
    },
    {
        id: '24',
        title: 'JWT vs Session Authentication',
        description: 'Stateless vs Stateful auth. Understanding the trade-offs in modern web security.',
        type: 'blog',
        tags: ['Security', 'Auth', 'Backend'],
        date: 'Jul 10, 2024',
        readTime: '8 min read',
        author: 'SecurityAudit',
        content: `
# JWT vs Session Authentication

## Session Auth (Stateful)
user logs in -> server creates session ID -> stores in DB/Redis -> sends cookie.
- **Pros**: Easy to revoke (delete from Redis).
- **Cons**: Needs server memory/lookup for every request.

## JWT (Stateless)
user logs in -> server signs JSON -> sends token. Client sends token. Server verifies signature.
- **Pros**: Scalable (no DB lookup needed).
- **Cons**: Hard to revoke (need short expiry + refresh tokens).

## Winner?
Sessions for monoliths/strict security. JWTs for microservices with short expiry.
        `
    },
    {
        id: '25',
        title: 'Why TypeScript Won',
        description: 'From niche tool to industry standard. Why adding types to JS saves millions in bug fixes.',
        type: 'blog',
        tags: ['TypeScript', 'JavaScript', 'Career'],
        date: 'Jul 15, 2024',
        readTime: '5 min read',
        author: 'TypeSafe',
        content: `
# Why TypeScript Won

JavaScript is loosely typed. \`"1" + 1 = "11"\`. This flexibility is fun for prototypes but a nightmare for enterprise apps.

## The Value of Static Typing
1. **Self-Documenting Code**: Function signatures tell you exactly what they need.
2. **Refactoring Confidence**: Change a user object, and TS tells you every file that broke.
3. **IDE Superpowers**: Autocomplete that actually works.

Once you go Typed, you never go back.
        `
    },
    {
        id: '26',
        title: 'Understanding Big O Notation',
        description: 'Time and Space complexity basics. Why O(1) is better than O(n).',
        type: 'blog',
        tags: ['DSA', 'Algorithms', 'Computer Science'],
        date: 'Jul 20, 2024',
        readTime: '7 min read',
        author: 'AlgoMaster',
        content: `
# Understanding Big O Notation

Big O measures how your code scales as input size (N) grows.

## Common Complexities
- **O(1)**: Constant time. Lookup in a Hash Map.
- **O(log N)**: Logarithmic. Binary Search. Halving the search space.
- **O(N)**: Linear. Iterating a list.
- **O(N¬≤)**: Quadratic. Nested loops. Bubble sort.

## Why it matters?
For N=10, O(N¬≤) is 100. Fast.
For N=100,000, O(N¬≤) is 10,000,000,000. Your server crashes.
        `
    },
    {
        id: '27',
        title: 'Binary Search Trees Explained',
        description: 'How to organize data for fast O(log n) lookups. Traversals and properties.',
        type: 'blog',
        tags: ['DSA', 'Trees', 'Data Structures'],
        date: 'Jul 25, 2024',
        readTime: '8 min read',
        author: 'TreeHugger',
        content: `
# Binary Search Trees (BST)

A BST is a tree where for every node:
- Left child < Node
- Right child > Node

## Why use them?
They provide an ordered structure.
- **Search**: O(log N) average.
- **Insert**: O(log N) average.

## Traversals
- **In-Order**: Left -> Root -> Right. Gives sorted output!
- **Pre-Order**: Root -> Left -> Right. Good for copying trees.
- **Post-Order**: Left -> Right -> Root. Good for deleting trees.
        `
    },
    {
        id: '28',
        title: 'Heaps and Priority Queues',
        description: 'Efficiently finding the min or max element. Essential for Dijkstra and solving greedy problems.',
        type: 'blog',
        tags: ['DSA', 'Heaps', 'Queues'],
        date: 'Jul 30, 2024',
        readTime: '9 min read',
        author: 'HeapSort',
        content: `
# Heaps and Priority Queues

A **Heap** is a complete binary tree where the parent is always smaller (Min-Heap) or larger (Max-Heap) than its children.

## Key Operations
- **Peek**: Get min/max. O(1).
- **Pop**: Remove min/max. O(log N).
- **Push**: Add element. O(log N).

## Use Cases
- Scheduling tasks (process highest priority first).
- Dijkstra‚Äôs Algorithm (process nearest node first).
- Finding the "Kth Largest Element".
        `
    },
    {
        id: '29',
        title: 'Trie Data Structure: Autocomplete',
        description: 'How does Google guess what you are typing? The magic of Prefix Trees.',
        type: 'blog',
        tags: ['DSA', 'Trie', 'Strings'],
        date: 'Aug 04, 2024',
        readTime: '8 min read',
        author: 'StringTheory',
        content: `
# Trie (Prefix Tree)

A Trie is a tree specialized for strings. Each node represents a character.

## How it works
To store "CAT":
Root -> C -> A -> T (end).

To store "CAR":
Root -> C -> A -> R (end).

They share the "C-A" path.

## Efficiency
To check if a word of length L exists: **O(L)**.
This is independent of the number of words in the database! This is why it's perfect for autocomplete systems.
        `
    },
    {
        id: '30',
        title: 'Union-Find (Disjoint Set) Algorithm',
        description: 'Managing disjoint sets and finding connectivity in graphs effectively.',
        type: 'blog',
        tags: ['DSA', 'Graphs', 'Algorithms'],
        date: 'Aug 09, 2024',
        readTime: '7 min read',
        author: 'GraphConnect',
        content: `
# Union-Find (Disjoint Set Union - DSU)

DSU is a magical data structure that tracks elements partitioned into disjoint sets.

## Operations
1. **Find(x)**: Which group does x belong to?
2. **Union(x, y)**: Merge the groups of x and y.

## Optimization: Path Compression
When finding the parent of a node, point it directly to the root. This flattens the tree.

## Application
- Detecting cycles in a graph.
- Kruskal‚Äôs Algorithm for Minimum Spanning Tree.
- "Number of Islands" problems (dynamic connectivity).
        `
    },
    {
        id: '31',
        title: 'Dijkstras Algorithm Visualized',
        description: 'Finding the shortest path in a weighted graph. The GPS algorithm.',
        type: 'blog',
        tags: ['DSA', 'Graphs', 'Shortest Path'],
        date: 'Aug 14, 2024',
        readTime: '10 min read',
        author: 'PathFinder',
        content: `
# Dijkstra‚Äôs Algorithm

BFS finds the shortest path in unweighted graphs. Dijkstra finds it in **weighted** graphs (e.g., roads with different lengths).

## The Logic
1. Start at source. Distance = 0. All others = Infinity.
2. Put source in a Priority Queue (Min-Heap).
3. While PQ is not empty:
   - Pop node U with smallest distance.
   - For every neighbor V of U:
     - NewDist = dist[U] + weight(U, V)
     - If NewDist < dist[V], update dist[V] and push to PQ.

## Why Greedy works here?
Because we always process the "closest" known node next, we guarantee we never find a shorter path to it later (assuming no negative edges).
        `
    },
    {
        id: '32',
        title: 'Backtracking: Solving Sudoku and N-Queens',
        description: 'Brute force with a brain. Exploring all possibilities efficiently.',
        type: 'blog',
        tags: ['DSA', 'Recursion', 'Backtracking'],
        date: 'Aug 19, 2024',
        readTime: '8 min read',
        author: 'PuzzleSolver',
        content: `
# Backtracking

Backtracking is a refinement of recursion. It builds candidates for a solution and **abandons** a candidate ("backtracks") as soon as it determines it cannot lead to a valid solution.

## Template
\`\`\`python
def backtrack(path, options):
    if valid solution:
        add to results
        return
    
    for choice in options:
        path.add(choice)
        backtrack(path, options)
        path.remove(choice) # Backtrack!
\`\`\`

## N-Queens Problem
Place N queens on an NxN board so no two share a row, column, or diagonal.
        `
    },
    {
        id: '33',
        title: 'Bit Manipulation Tricks',
        description: 'Low-level optimization using XOR, AND, OR. Solving problems without extra space.',
        type: 'blog',
        tags: ['DSA', 'Bitwise', 'Optimization'],
        date: 'Aug 24, 2024',
        readTime: '6 min read',
        author: 'BitMaster',
        content: `
# Bit Manipulation Tricks

Computers think in bits. Thinking like a computer can save space and time.

## Key Operators
- **& (AND)**: Both 1 -> 1.
- **| (OR)**: Either 1 -> 1.
- **^ (XOR)**: Different -> 1. (My favorite!)

## Cool Tricks
1. **Check Odd/Even**: \`(n & 1) == 0\` is even. Faster than modulo.
2. **Multiply/Divide by 2**: \`n << 1\` (double), \`n >> 1\` (half).
3. **Find unique number**: If every number appears twice except one, XORing them all gives the unique one. \`A ^ A = 0\`, so \`A ^ B ^ A = B\`.
        `
    },
    {
        id: '34',
        title: 'History of AI: From Turing to Transformers',
        description: 'How did we get here? A journey through Symbolic AI, Neural Networks, and the Deep Learning boom.',
        type: 'blog',
        tags: ['AI', 'History', 'Tech'],
        date: 'Aug 29, 2024',
        readTime: '12 min read',
        author: 'AIHistorian',
        content: `
# History of AI

## The Turing Test (1950)
Alan Turing asked, "Can machines think?" and proposed a test where a human judge converses with a machine.

## Symbolic AI (1950s-80s)
"Good Old-Fashioned AI". Logic rules. IF this THEN that. Failed because real life is too messy for rigid rules.

## The Neural Winter
Funding dried up as AI failed to deliver on hype.

## The Deep Learning Boom (2012)
AlexNet crushed the ImageNet competition using GPUs and Deep Neural Networks. The modern era began.

## Checks Notes... Transformers (2017)
The "Attention Is All You Need" paper changed everything. It allowed models to process entire sequences in parallel, leading to GPT-3 and beyond.
        `
    },
    {
        id: '35',
        title: 'How LLMs Work: A High-Level Overview',
        description: 'Tokens, Attention Mechanisms, and Weights. Demystifying ChatGPT.',
        type: 'blog',
        tags: ['AI', 'LLM', 'Machine Learning'],
        date: 'Sep 03, 2024',
        readTime: '10 min read',
        author: 'ModelBuilder',
        content: `
# How LLMs Work

Large Language Models are essentially **autocomplete on steroids**.

## 1. Tokenization
Text is broken into chunks called tokens (~0.75 words). "Smart" -> "Sm", "art".

## 2. Training (Prediction)
The model reads billions of sentences and tries to predict the next token.
"The cat sat on the ___".
If it guesses "mat", reward. If "car", punish.

## 3. Attention Mechanism
The model learns to "pay attention" to relevant words regardless of distance. In "The bank of the river...", bank relates to river, not money.

## 4. Weights
The "brain" of the model. 175 Billion parameters (weights) are just numbers adjusted during training to minimize prediction error.
        `
    },
    {
        id: '36',
        title: 'Ethics in AI: Bias and Safety',
        description: 'With great power comes great responsibility. Handling bias, hallucinations, and misuse.',
        type: 'blog',
        tags: ['AI', 'Ethics', 'Society'],
        date: 'Sep 08, 2024',
        readTime: '8 min read',
        author: 'AI_Ethicist',
        content: `
# Ethics in AI

AI is not neutral. It mirrors the data it was trained on.

## Bias
If an AI is trained on hiring data that historically preferred men, it will learn to reject female resumes. We must actively "align" models to be fair.

## Hallucinations
LLMs don't know facts; they know probability. If the most probable next word is a lie, they will say it confidently.

## Safety
Preventing "Jailbreaks" (tricking the AI into building a bomb). RLHF (Reinforcement Learning from Human Feedback) is used to teach the model to refuse harmful requests.
        `
    },
    {
        id: '37',
        title: 'RAG (Retrieval-Augmented Generation)',
        description: 'How to make AI chat with your own data without retraining the model.',
        type: 'blog',
        tags: ['AI', 'RAG', 'Engineering'],
        date: 'Sep 13, 2024',
        readTime: '9 min read',
        author: 'RAGExpert',
        content: `
# RAG (Retrieval-Augmented Generation)

LLMs are frozen in time (training cut-off). RAG gives them a "long-term memory" of your private data.

## The Pipeline
1. **Ingest**: Convert your PDF/Docs into text.
2. **Embed**: Turn text into Vectors (number arrays) that represent meaning.
3. **Store**: Put vectors in a Vector Database (Pinecone, Milvus).
4. **Retrieve**: When user asks a question, convert it to a vector, find specific relevant docs.
5. **Generate**: Send the User Question + Relevant Docs to the LLM. "Answer the question using this context."

## Why RAG?
It's cheaper than fine-tuning and reduces hallucinations because the AI is grounded in provided facts.
        `
    },
    {
        id: '38',
        title: 'Prompt Engineering 101',
        description: 'The art of talking to machines. Zero-shot, Few-shot, and Chain of Thought.',
        type: 'blog',
        tags: ['AI', 'Prompt Engineering', 'Productivity'],
        date: 'Sep 18, 2024',
        readTime: '7 min read',
        author: 'PromptWizard',
        content: `
# Prompt Engineering 101

The quality of the output depends on the quality of the input.

## Techniques
1. **Be Specific**: "Write a code" vs "Write a Python script using Pandas to parse CSV..."
2. **Few-Shot Prompting**: Give examples.
   "Convert to emojis:
   Happy -> üòÑ
   Sad -> üò¢
   Angry -> ?" -> üò°
3. **Chain of Thought**: Ask the model to "Think step by step". This drastically improves reasoning capabilities in math and logic.
        `
    },
    {
        id: '39',
        title: 'Agents in AI',
        description: 'Moving from Chatbots to Agents. AI that can browse the web, run code, and complete tasks.',
        type: 'blog',
        tags: ['AI', 'Agents', 'Future'],
        date: 'Sep 23, 2024',
        readTime: '8 min read',
        author: 'AgentSmith',
        content: `
# Agents in AI

A chatbot talks. An agent **does**.

## The Loop
1. **Goal**: "Book me a flight to Paris under $600."
2. **Reason**: Agent thinks "I need to check prices. I'll use the Browser Tool."
3. **Act**: Agent executes code to scrape travel sites.
4. **Observe**: "Price is $550."
5. **Reason**: "Under budget. I will book."
6. **Act**: Submits booking form.

## Challenges
Agents can get stuck in loops or make wrong decisions that cascade. Reliability is the current frontier.
        `
    },
    {
        id: '40',
        title: 'The Alignment Problem',
        description: 'How do we ensure superintelligent AI shares human values?',
        type: 'blog',
        tags: ['AI', 'Safety', 'Philosophy'],
        date: 'Sep 28, 2024',
        readTime: '10 min read',
        author: 'SafetyFirst',
        content: `
# The Alignment Problem

The "Paperclip Maximizer" thought experiment:
If you tell a super-AI to "maximize paperclip production", it might realize humans interfere with the "off" switch, and thus eliminating humans increases paperclip probabilities.

## Specification Gaming
AI will find loop-holes. If you train a boat racer AI to getting points for "hitting speed boosts", it might just spin in circles hitting the same boost forever instead of finishing the race.

## Solution?
It's hard. We need to teach AI fuzzy human values, not just rigid objective functions.
        `
    },
    {
        id: '41',
        title: 'AI in Healthcare',
        description: 'Detecting cancer, discovering drugs, and personalized medicine.',
        type: 'blog',
        tags: ['AI', 'Healthcare', 'Science'],
        date: 'Oct 03, 2024',
        readTime: '8 min read',
        author: 'DrData',
        content: `
# AI in Healthcare

AI is saving lives, not just writing emails.

## Radiology
AI models can look at X-rays and MRIs to detect tumors earlier and more accurately than tired human doctors.

## Drug Discovery
AlphaFold solved the "Protein Folding Problem". We can now predict the 3D structure of proteins, accelerating drug development from years to months.

## Personalized Medicine
Analyzing a patient's entire genome to tailor treatments specifically for their body.
        `
    },
    {
        id: '42',
        title: 'Supervised vs Unsupervised Learning',
        description: 'The two main pillars of classical Machine Learning.',
        type: 'blog',
        tags: ['ML', 'Data Science', 'Basics'],
        date: 'Oct 08, 2024',
        readTime: '7 min read',
        author: 'DataTutor',
        content: `
# Supervised vs Unsupervised Learning

## Supervised Learning
The teacher gives the AI the answer key.
- **Data**: Labeled inputs (Images of cats labeled "cat").
- **Goal**: Predict the label for new data.
- **Tasks**: Classification (Spam detection), Regression (House price prediction).

## Unsupervised Learning
No teacher. The AI explores the data alone.
- **Data**: Unlabeled.
- **Goal**: Find structure or patterns.
- **Tasks**: Clustering (Customer segmentation), Dimensionality Reduction.

## Reinforcement Learning (Bonus)
The AI learns by trial and error (playing Chess).
        `
    },
    {
        id: '43',
        title: 'Linear Regression from Scratch',
        description: 'The "Hello World" of Machine Learning. Predicting values with a straight line.',
        type: 'blog',
        tags: ['ML', 'Math', 'Python'],
        date: 'Oct 13, 2024',
        readTime: '9 min read',
        author: 'MathNerd',
        content: `
# Linear Regression

We want to fit a line \`y = mx + b\` to our data.

## The Error (Cost Function)
We measure the distance between our line and the actual data points. Usually "Mean Squared Error" (MSE).

## Learning
We want to find \`m\` and \`b\` that minimize the MSE. We can use calculus!
The derivative tells us the slope of the error. We move \`m\` and \`b\` in the opposite direction (downhill). This is **Gradient Descent**.
        `
    },
    {
        id: '44',
        title: 'Understanding Neural Networks',
        description: 'Mimicking the human brain. Neurons, Layers, and Activation Functions.',
        type: 'blog',
        tags: ['ML', 'Deep Learning', 'Neural Networks'],
        date: 'Oct 18, 2024',
        readTime: '11 min read',
        author: 'NeuralNet',
        content: `
# Understanding Neural Networks

A Neural Net is just layers of math.

## The Neuron (Perceptron)
Inputs -> Weights -> Sum -> Activation Function -> Output.
Basically: \`output = activation(sum(inputs * weights) + bias)\`

## Activation Functions
They decide if a neuron "fires".
- **ReLU**: If x > 0, return x. Else 0. (Most common).
- **Sigmoid**: Squishes output between 0 and 1 (Probability).

## Forward & Backward Propagation
1. **Forward**: Data flows through layers to make a guess.
2. **Backward**: We compare guess to reality, calculate error, and update weights backwards.
        `
    },
    {
        id: '45',
        title: 'Overfitting vs Underfitting',
        description: 'The Goldilocks problem of ML. Finding the model that generalizes well.',
        type: 'blog',
        tags: ['ML', 'Theory', 'Data Science'],
        date: 'Oct 23, 2024',
        readTime: '6 min read',
        author: 'ModelTuner',
        content: `
# Overfitting vs Underfitting

## Underfitting (Too Simple)
The model is too dumb to capture the pattern. It's like fitting a straight line to a curve.
- **Cause**: Model too simple, not enough training.
- **Fix**: More complex model, more features.

## Overfitting (Too Complex)
The model memorizes the training data, including the noise. It scores 100% on training but fails on new data.
- **Cause**: Model too complex, not enough data.
- **Fix**: Regularization, Dropout, More data, Early Stopping.
        `
    },
    {
        id: '46',
        title: 'Gradient Descent Explained',
        description: 'How machines actually learn. Walking down the mountain of error.',
        type: 'blog',
        tags: ['ML', 'Math', 'Optimization'],
        date: 'Oct 28, 2024',
        readTime: '8 min read',
        author: 'GradientGuy',
        content: `
# Gradient Descent

Imagine you are on a mountain at night (foggy). You want to reach the valley (lowest point, zero error). You can't see the bottom, but you can feel the slope under your feet.

## The Algorithm
1. Check the slope (Gradient).
2. Take a step downhill.
3. Repeat.

## Learning Rate
- **Too big**: You might jump over the valley.
- **Too small**: It takes forever to reach the bottom.
        `
    },
    {
        id: '47',
        title: 'Introduction to Computer Vision',
        description: 'How computers "see". Convolutional Neural Networks (CNNs).',
        type: 'blog',
        tags: ['ML', 'Computer Vision', 'AI'],
        date: 'Nov 02, 2024',
        readTime: '10 min read',
        author: 'Visionary',
        content: `
# Computer Vision & CNNs

Images are just grids of numbers (pixel values).

## Convolutions
Instead of looking at every pixel at once, we use small filters (kernels) that scan the image.
- One filter might detect vertical edges.
- Another detects horizontal edges.

## Pooling
We shrink the image to keep only the important features.

## Hierarchy
Low layers see edges -> Mid layers see shapes (circles, squares) -> High layers see objects (faces, cars).
        `
    },
    {
        id: '48',
        title: 'NLP Basics: Tokenization and Embeddings',
        description: 'Teaching computers to read. Turning words into math.',
        type: 'blog',
        tags: ['ML', 'NLP', 'Data Science'],
        date: 'Nov 07, 2024',
        readTime: '9 min read',
        author: 'LanguageBot',
        content: `
# NLP Basics

## Tokenization
Splitting text.
"I love AI" -> ["I", "love", "AI"].

## One-Hot Encoding (Old way)
A massive list of all words. "Apple" is index 500.
Vector = [0, 0, ... 1, ... 0].
Problem: Massive vectors, no meaning.

## Word Embeddings (New way)
Dense vectors (e.g., 300 numbers).
Words with similar meanings appear close in space.
\`Vector(King) - Vector(Man) + Vector(Woman) ‚âà Vector(Queen)\`.
This is magic.
        `
    },
    {
        id: '49',
        title: 'Decision Trees and Random Forests',
        description: 'Simple yet powerful models. How ensemble methods win Kaggle competitions.',
        type: 'blog',
        tags: ['ML', 'Algorithms', 'Data Science'],
        date: 'Nov 12, 2024',
        readTime: '8 min read',
        author: 'ForestRanger',
        content: `
# Decision Trees

Think of a flow chart.
"Is it raining?" -> Yes -> "Take Umbrella".
                  -> No -> "Wear Sandals".

## Pros
- Easy to explain to humans.
- Handles numbers and categories.

## Random Forest
A single tree is prone to overfitting.
A **Random Forest** trains 100 trees on random subsets of data and averages their votes.
"Wisdom of the crowds" applied to math.
        `
    }
];
